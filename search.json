[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto CRC Book",
    "section": "",
    "text": "Preface\nThis is a Quarto book."
  },
  {
    "objectID": "index.html#software-conventions",
    "href": "index.html#software-conventions",
    "title": "Quarto CRC Book",
    "section": "Software conventions",
    "text": "Software conventions\n\n1 + 1\n\n2\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Quarto CRC Book",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nBlah, blah, blah…"
  },
  {
    "objectID": "detikcom.html",
    "href": "detikcom.html",
    "title": "1  CINDY LAUNDIYA MARETHA",
    "section": "",
    "text": "2 210411100037\n\n!pip install beautifulsoup4\n\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\nRequirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nimport csv\nhades = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}\n\n\n\n3 1. Crawling Berita\nPada proses crawling ini diambil berita melalui website detik.com dengan menggunakan kata kunci “Pemanasan Global”\n\ndef scrape_detik(hal, requests):\n    a = 1\n    # Membuka file CSV untuk menulis hasil scraping\n    with open('hasil_scraping.csv', 'w', newline='', encoding='utf-8') as csvfile:\n        fieldnames = ['Judul', 'Waktu', 'Link', 'Content']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        # Menulis header ke dalam file CSV\n        writer.writeheader()\n\n        for page in range(1, hal):\n            url = f'https://www.detik.com/search/searchall?query=pemanasan+global&siteid=2{page}'\n            req = requests.get(url)\n            sop = BeautifulSoup(req.text, 'html.parser')\n            li = sop.find('div', class_='list media_rows list-berita')\n            lin = li.find_all('article')\n\n            for x in lin:\n                link = x.find('a')['href']\n                date = x.find('a').find('span', class_='date').text.replace('WIB','').replace('detikJatim','').split(',')[1]\n                headline = x.find('a').find('h2').text\n\n                ge_ = requests.get(link).text\n                sop_ = BeautifulSoup(ge_, 'html.parser')\n                content = sop_.find_all('div', class_='detail__body-text itp_bodycontent')\n\n                for cont in content:\n                    paragraphs = cont.find_all('p')\n                    content_ = ''.join([p.text for p in paragraphs]).replace('\\n', '').replace('ADVERTISEMENT','').replace('SCROLL TO RESUME CONTENT','')\n\n                    data = {\n                        'Judul': headline,\n                        'Waktu': date,\n                        'Link': link,\n                        'Content': content_\n                    }\n                    # Menulis data ke dalam file CSV\n                    writer.writerow(data)\n                    print(\"Data berhasil ditambahkan:\", data)\n                    print(f'done[{a}] &gt; {headline}')\n                    a += 1\n\n\nscrape_detik(3, requests)\n\nData berhasil ditambahkan: {'Judul': 'Hampir 8.000 Pelari Meriahkan Lazada Run di ICE BSD, Ada dari Kenya', 'Waktu': ' 11 Jun 2023 11:58 ', 'Link': 'https://sport.detik.com/sport-lain/d-6766479/hampir-8-000-pelari-meriahkan-lazada-run-di-ice-bsd-ada-dari-kenya', 'Content': 'Sekitar 8.000 peserta meriahkan ajang lari yang digelar Lazada Indonesia bertajuk Lazada Run di ICE BSD, Kabupaten Tangerang. Para peserta lomba lari ini tak hanya dari dalam kota, tetapi juga datang dari luar kota bahkan luar negara, salah satunya, Kenya.Chief Marketing Officer Lazada Indonesia mengatakan untuk kategori kegiatan ini dibagi menjadi 5K, 10K, dan 21K. Semuanya terbuka untuk umum dan masyarakat.\"Pesertanya kita terbuka untuk semua. Mau yang sport enthusiast, professional runners, anak-anak, community running, atau yang memang ingin mendapatkan experience di Lazada Run,\" ujar Intan pada detikcom, Minggu (11/6/2023).\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\rIntan melanjutkan kegiatan ini digelar untuk mendorong pola hidup sehat masyarakat. Karena mencakup semua masyarakat, kegiatan ini digelar ke beberapa kategori. Harapannya yang bisa sehat bukan hanya individual, tetapi juga keluarga di Indonesia.\"Kemudian kita ingin berkontribusi, terutama dari Kemenparekraf, kita ingin berkontribusi dalam bagian mendorong sport tourism di Indonesia,\" imbuhnya.Dia menambahkan, Lazada juga ingin memberikan bukan hanya pengalaman berbelanja online yang menyenangkan, tetapi juga memberikan sesuatu dalam hidup mereka. Salah satunya adalah melalui kegiatan Lazada Run.\"Kita ingin menambahkan sehat dalam hidup mereka.\" kata Intan.Selain itu, Deputi Bidang Produk Wisata dan Penyelenggara Kegiatan Kemenparekraf, Vinsensius Jemadu mengatakan pihaknya mengapresiasi dan berterima kasih atas kegiatan Lazada Run. Menurutnya kegiatan Lazada bisa ikut mendorong pariwisata di Indonesia. Sebab, baru pertama kali digelar kegiatan ini sudah diikuti hampir 8.000 peserta.\"Ini baru pertama kali sudah 8.000. Artinya apa? Kegiatan kedua, ketiga, nanti pasti akan naik,\" ucap Vinsensius.Melihat semangat dan antusias peserta yang luar biasa, dia pun meminta kepada pihak Lazada untuk menjadikan kegiatan Lazada Run sebagai salah satu kegiatan rutin yang dilakukan.\"Kami juga menantang Lazada untuk menggelar event naik kelas yang menjadi event global. Tentunya Kemenparekraf, khususnya bagian event akan siap mendukung. Kalau bisa suatu saat, maraton ini digelar di Danau Toba, atau di Labuan Bajo untuk bisa naik kelas,\" terangnya.Selain itu, antusiasme dan semangat bisa dilihat dari ramainya peserta yang memadati kawasan ICE BSD sejak pukul 4.30 pagi. Sebelum berlari sesuai kategori, para peserta juga diajak untuk melakukan pemanasan bersama Lazada.Salah satu peserta, Nunu dari Serpong pun mengatakan dirinya juga antusias mengikuti kegiatan ini. Bersama dengan 3 temannya, Nunu telah datang sejak pagi dan berhasil menyelesaikan maraton untuk kategori 5K.\"Saya suka lari, hobi. Terus Lazada Run disponsori produk bagus. Kegiatan ini seru, larinya disemangatin,\" ungkap Nunu.Selain Nunu, salah satu peserta yang semangat mengikuti kegiatan ini adalah Tata dari Jakarta. Bersama kedua temannya, dia mengikuti maraton dengan kategori\"Ini acaranya rame banget, banyak teman-teman lari juga. Jadi sekalian latihan nanti ada half marathon jadi time trial aja sih,\" ungkap Tata.Tata menceritakan untuk mengikuti kegiatan lari seperti ini, dia bersama temannya juga terbiasa untuk latihan. Mereka juga bahkan memiliki pelatih dan menjaga pola makan tersendiri, salah satunya tidak makan gorengan. Selain itu, Tata dan temannya berharap kegiatan Lazada Run 2023 juga bisa terus digelar di tahun selanjutnya.Diketahui, kegiatan Lazada Run 2023 adalah salah satu kegiatan yang digelar oleh Lazada di 6 negara di Asia Tenggara. Setelah sebelumnya pertama kali digelar di Vietnam pada April 2023, kegiatan final Lazada Run bakal di Singapura pada Juli 2023 mendatang.'}\ndone[1] &gt; Hampir 8.000 Pelari Meriahkan Lazada Run di ICE BSD, Ada dari Kenya\nData berhasil ditambahkan: {'Judul': 'Hari Lari Sedunia, 200 Pelari Ikut Fun Run Under Armour di Jakarta', 'Waktu': ' 01 Jun 2022 11:17 ', 'Link': 'https://sport.detik.com/sport-lain/d-6105077/hari-lari-sedunia-200-pelari-ikut-fun-run-under-armour-di-jakarta', 'Content': 'Brand apparel olahraga Under Armour mengadakan kompetisi lari \\'All Out Mile\\' dalam rangkap Hari Lari Sedunia. Kegiatan yang diadakan di Senayan, Jakarta, ini diikuti sebanyak 200 peserta, mulai dari orang dewasa hingga anak-anak. Under Armour juga mengundang 11 komunitas lari.\"Kita undang komunitas lari. Sebenarnya kita cuma memberikan slot (peserta) terbatas. Tapi ini acaranya super sukses karena ramai banget. Intinya kita undang semua masyarakat untuk ikut merayakan global running day,\" ujar Marketing Manager Under Armour Indonesia Ade Maharani saat ditemui di lokasi, Rabu (1/6/2022).Menurut Ade, kegiatan ini menjadi ajang untuk mengukur hasil latihan selama ini. Sekaligus sebagai pemanasan menghadapi challenge yang sesungguhnya. Dikatakannya, selama Fun Run 4K berlangsung peserta dibagi ke dalam beberapa grup, dan mereka bisa memilih kelompok yang sesuai dengan kecepatan masing-masing.\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r\"Kita mendukung semua orang yang ingin bersenang-senang. Untuk membantu mempersiapkan diri juga sebelum ikut challenge, sudah berhasil atau belum dari hasil selama latihan,\" jelasnya.Untuk diketahui, All Out Mile merupakan sebuah kompetisi lari global yang berlangsung secara bersamaan di 14 negara. Adapun proses pendaftarannya sudah dibuka sejak 1 Mei 2022 lalu, sementara pelaksanaan window competition akan berlangsung mulai dari hari ini sampai 5 Juni 2022 mendatang. Agenda ini dikuti 400 peserta dari Eropa, Amerika Serikat, dan South Asia Pasific.  Selama periode itu, peserta individu maupun secara kelompok ditantang untuk berlari sejauh 1 mil atau 1,6 Km. Hasil data berlari peserta secara otomatis akan ditarik dari aplikasi UA MapMyRunâ\\x84¢ dan akan muncul di dalam situs FitRangkings dalam bentuk papan klasemen, di mana para peserta bisa melihat urutan/ranking masing-masing.Ade mengatakan tujuan utama event All Out Mile yaitu untuk mengajak masyarakat kembali berlari setelah 2 tahun terhalang oleh pandemi. Mengingat jaraknya yang hanya 1 mil atau 1,6 Km maka kegiatan ini cocok untuk diikuti oleh pemula.\"Kita juga mengajak masyarakat kembali ke realita, back to run. Jadi semacam reuni lagi. Apalagi sudah berapa tahun kita (dilanda) pandemi. Jadi rasanya ini waktu yang tepat untuk mendapatkan first 1 mile lagi setelah pandemi,\" tuturnya.Baca SelengkapnyaHalaman                1                            2                            Selanjutnya Simak Video \"Jeon So Min Cabut dari Running Man\"[Gambas:Video 20detik]olahraga lari running jogging under armour '}\ndone[2] &gt; Hari Lari Sedunia, 200 Pelari Ikut Fun Run Under Armour di Jakarta\nData berhasil ditambahkan: {'Judul': 'PBSI Maklum Singapore Open Batal, tapi...', 'Waktu': ' 13 Mei 2021 15:25 ', 'Link': 'https://sport.detik.com/raket/d-5568632/pbsi-maklum-singapore-open-batal-tapi', 'Content': 'PP PBSI menilai wajar keputusan Badminton World Federation (BWF) yang membatalkan Singapore Open 2021, sekalipun merugikan salah satu atletnya.BWF secara resmi membatalkan turnamen BWF super 500 yang seharusnya bergulir 1-6 Juni mendatang. Kasus pandemi virus Corona yang meningkat secara global menjadi alasan mereka mengambil keputusan tersebut.Keputusan itu sudah diketahui PBSI. Melalui Kepala bidang Pembinaan Prestasi, Rionny Mainaky, induk federasi bulutangkis nasional itu memberikan responsnya. Seperti apa?\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r\"Setelah turnamen Malaysia Open batal terselenggara, dari awal saya memprediksi Singapura juga akan batal, karena pandemi COVID-19. Apalagi melihat aturan pemerintah Singapura dan protokol kesehatannya yang ketat, sangat tidak memungkinkan bagi atlet untuk bisa tampil maksimal,\" kata Rionny dalam keterangan tertulisnya.\"Jadi saya kira wajar saja kalau BWF akhirnya membatalkannya. Pembatalan itu juga keputusan yang tepat walau sangat merugikan bagi pemain kita, terutama Hafiz Faizal/Gloria Emanuelle Widjaja yang tengah berjuang lolos Olimpiade Tokyo,\" dia menambahkan.Bagaimanapun, Hafiz/Gloria saat ini berada di peringkat sembilan dalam daftar kualifikasi Olimpiade. Berdasarkan regulasi (BWF), setiap negara bisa mengirimkan dua wakil jika kedua pasangan berada di top 8.Sedangkan, Singapore Open 2021 menjadi satu-satunya turnamen untuk bisa menyodok kembali peringkat mereka masuk ke delapan besar. Dengan catatan, hasil pertandingan mereka juga bagus.\"Sementara bagi atlet kita yang lain tidak ada ajang pemanasan sebelum tampil di Olimpiade nanti,\" ujar Rionny.Pelatih ganda campuran Richard Mainaky, juga mengungkapkan kekecewaannya. Dia menyayangkan karena atletnya tengah berjuang untuk lolos.\"Saya sangat menyayangkan karena dengan batalnya turnamen ini cukup merugikan posisi Hafiz/Gloria yang tengah berjuang mengamankan ranking untuk bisa tampil Olimpiade,\" katanya.Selain Singapore Open, sebelumnya Malaysia Open, India Open, German Open, dan Kejuaraan Asia juga mengalami penundaan lantaran wabah COVID-19. Seluruh turnamen tersebut merupakan kualifikasi untuk menambah poin Olimpiade 23 Juli-8 Agustus 2021.'}\ndone[3] &gt; PBSI Maklum Singapore Open Batal, tapi...\nData berhasil ditambahkan: {'Judul': 'Kualifikasi Olimpiade Mulai 2021, Richard Mainaky: Tahun Ini Pemanasan', 'Waktu': ' 04 Jun 2020 14:29 ', 'Link': 'https://sport.detik.com/raket/d-5040253/kualifikasi-olimpiade-mulai-2021-richard-mainaky-tahun-ini-pemanasan', 'Content': 'Pelatih bulutangkis ganda campuran Richard Mainaky tak mempermasalahkan keputusan BWF mengaktifkan kembali perhitungan poin Olimpiade mulai tahun depan. Ia menyebut turnamen di tahun ini bisa buat pemanasan.Praveen Jordan Cs tercatat sudah lebih dari dua bulan tanpa turnamen. Kosongnya agenda pertandingan adalah imbas dari virus Corona yang terjadi secara global. Mereka pun hanya menjalani latihan tertutup dengan intensitas setengah porsi.Belakangan, BWF mengumumkan akan menggulirkan kompetisi mulai pertengahan Agustus. Hyderabad Open 2020 di India menjadi turnamen pembuka. Tapi turnamen-turnamen yang digelar tahun ini poinnya tidak masuk dalam kualifikasi Olimpiade Tokyo tahun depan.\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\rRichard tidak masalah dengan keputusan BWF itu. Kakak kandung Rexy mainaky itu tetap melakukan persiapan untuk atletnya, sebagai pemanasan sebelum tancap gas menuju pertandingan yang lebih besar.\"Tahun ini sebenarnya masih belum jelas. Ada kemungkinan batal juga karena wabah ini kita tidak tahu sampai kapan (berakhirnya). Tapi kami tetap persiapkan. Jadi dari awal Juni itu saya bilang ke asisten pelatih, Nova (Widianto), ada program dan harus jalan,\" kata Richard kepada detikSport, Kamis (4/6/2020).\"Akan tetapi latihan di masa pandemi ini latihan fisiknya tak bisa lama-lama karena terkait dengan kondisi imunitas atlet. Jadi saya bilang ke Nova untuk fokus ke individu saja. Seperti Melati (Daeva Oktavianti) perkuat defense-nya. Lalu Praveen fokus kebugaran fisik dan jaga berat badan, begitupun dengan Gloria defense-nya masih perlu diperkuat.\"\"Kita memang tidak tahu seperti apa (kebijakan yang harus dilakukan) karena ada wabah ini, akan ada new normal segala. Tapi saya yakin step by step kami bisa atasi dan adaptasi. Jadi turnamen level 300 itu sebagai pemanasan menuju level 500 sampai 1000. Karena anak-anak butuh pertandingan setelah sekian lama vakum. Ya mudah-mudahan tidak ada pembatalan lagi. Supaya 2021 langsung tancap gas karena pas perhitungan kualifikasi Olimpiadenya,\" harap Richard.'}\ndone[4] &gt; Kualifikasi Olimpiade Mulai 2021, Richard Mainaky: Tahun Ini Pemanasan\nData berhasil ditambahkan: {'Judul': 'Piala Thomas dan Uber 2020 Jadi Oktober, PBSI: Waktunya Ideal', 'Waktu': ' 29 Apr 2020 22:25 ', 'Link': 'https://sport.detik.com/raket/d-4996515/piala-thomas-dan-uber-2020-jadi-oktober-pbsi-waktunya-ideal', 'Content': 'PP PBSI merespons keputusan Badminton World Federation (BWF) memundurkan kembali jadwal Piala Thomas dan Uber 2020. Oktober disebut sebagai waktu yang ideal.Awalnya, Piala Thomas dan Uber akan bergulir 16-24 Mei 2020 di Aahur, Denmark. BWF kemudian menundanya ke 15-23 Agustus setelah wabah virus corona meluas secara global.Kini, BWF kembali menunda lagi-lagi imbas COVID-19. Pemerintah Denmark mengeluarkan kebijakan larangan berkegiatan dalam skala besar sampai Agustus, sehingga pelaksanaan turnamen beregu itu paling mungkin digelar 3-11 Oktober 2020.\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\rSekretaris Jenderal PBSI Achmad Budiharto menyambut positif keputusan itu. Pasalnya, dia memprediksi bahwa virus Corona sudah mereda di bulan Agustus sehingga atletnya bisa melakukan persiapan normal.\"Kalau lihat perkiraan di Indonesia, puncak COVID-19 akan ada di bulan Mei, jadi Juli atau Agustus mudah-mudahan sudah bisa normal. Kalau perkiraan ini tepat, saya rasa Oktober ini waktu yang ideal,\" kata Budiharto dalam rilis yang diterima detikSport, Rabu (29/4/2020).\"Artinya, kami punya waktu dua bulan (Agustus-September untuk mematangkan persiapan. Meskipun, semua sangat bergantung pada turnamen sebelumnya,\" ucapnya.Hal ini, sebut Budiharto, berkaitan penyusunan strategi persiapan atlet dan pemanasan Kevin Sanjaya dkk setelah lebih dari sebulan tanpa kompetisi.'}\ndone[5] &gt; Piala Thomas dan Uber 2020 Jadi Oktober, PBSI: Waktunya Ideal\nData berhasil ditambahkan: {'Judul': 'Liga Equestrian Digelar Akhir Pekan Ini, Ada 1.000 Kursi Penonton Gratis', 'Waktu': ' 13 Des 2019 00:00 ', 'Link': 'https://sport.detik.com/sport-lain/d-4820926/liga-equestrian-digelar-akhir-pekan-ini-ada-1-000-kursi-penonton-gratis', 'Content': '\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r\"Equinara Academy Pulomas selama sepekan ini juga tengah menyelenggarakan Coaching Clinic dengan salah satu Akademi Equestrian Terbaik di Dunia yang berpusat di Jerman yaitu Longines World Equestrian Academy. Hal ini akan terus lakukan sebagai komitmen Equinara dalam mencetak para atlit berprestasi,\" sambung Adinda.Jakarta International Equestrian Park Pulomas (JIEPP) merupakan salah satu destinasi wisata olah raga yang dimiliki PT. Pulomas Jaya dan dikelola oleh PT. Equinara Global Prima.Venue ini memiliki fasilitas equestrian terbaik di Asia Tenggara dengan lahan seluas 35-hektar, kapasitas 1000 kursi tribun, 162 kandang kuda, arena pemanasan kuda, arena latihan (indoor dan outdoor), arena Cross Country, Rumah Sakit Hewan 24 Jam, pusat peternakan kuda jenis premium, serta akses LRT dan Bus Trans Jakarta.'}\ndone[6] &gt; Liga Equestrian Digelar Akhir Pekan Ini, Ada 1.000 Kursi Penonton Gratis\nData berhasil ditambahkan: {'Judul': 'Begini Cara Pegolf Lokal Cari Pengalaman', 'Waktu': ' 17 Des 2017 22:50 ', 'Link': 'https://sport.detik.com/sport-lain/d-3773992/begini-cara-pegolf-lokal-cari-pengalaman', 'Content': '\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r'}\ndone[7] &gt; Begini Cara Pegolf Lokal Cari Pengalaman\nData berhasil ditambahkan: {'Judul': 'Yang Perlu Diperbaiki Agar INASGOC Lebih Siap di Asian Games 2018', 'Waktu': ' 28 Nov 2017 13:55 ', 'Link': 'https://sport.detik.com/sport-lain/d-3746594/yang-perlu-diperbaiki-agar-inasgoc-lebih-siap-di-asian-games-2018', 'Content': '\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r'}\ndone[8] &gt; Yang Perlu Diperbaiki Agar INASGOC Lebih Siap di Asian Games 2018\nData berhasil ditambahkan: {'Judul': 'Pembukaan Olimpiade Rio: Tampilkan Favela dan Ajakan Hijaukan Hutan', 'Waktu': ' 06 Agu 2016 11:20 ', 'Link': 'https://sport.detik.com/sport-lain/d-3269718/pembukaan-olimpiade-rio-tampilkan-favela-dan-ajakan-hijaukan-hutan', 'Content': 'Awesome ð\\x9f\\x98\\x8d #OpeningCeremony #Rio2016 #olympics pic.twitter.com/OvMzvY14q0\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\rMetropolis ð\\x9f\\x8f¢ #OpeningCeremony #olympics pic.twitter.com/824pqCIcEW'}\ndone[9] &gt; Pembukaan Olimpiade Rio: Tampilkan Favela dan Ajakan Hijaukan Hutan\n\n\n\n\n4 Tampilan Data hasil Crawling Berita\n\nimport pandas as pd\ndf = pd.read_csv('/content/hasil_scraping.csv')\ndf\n\n\n  \n    \n\n\n\n\n\n\nJudul\nWaktu\nLink\nContent\n\n\n\n\n0\nHampir 8.000 Pelari Meriahkan Lazada Run di IC...\n11 Jun 2023 11:58\nhttps://sport.detik.com/sport-lain/d-6766479/h...\nSekitar 8.000 peserta meriahkan ajang lari yan...\n\n\n1\nHari Lari Sedunia, 200 Pelari Ikut Fun Run Und...\n01 Jun 2022 11:17\nhttps://sport.detik.com/sport-lain/d-6105077/h...\nBrand apparel olahraga Under Armour mengadakan...\n\n\n2\nPBSI Maklum Singapore Open Batal, tapi...\n13 Mei 2021 15:25\nhttps://sport.detik.com/raket/d-5568632/pbsi-m...\nPP PBSI menilai wajar keputusan Badminton Worl...\n\n\n3\nKualifikasi Olimpiade Mulai 2021, Richard Main...\n04 Jun 2020 14:29\nhttps://sport.detik.com/raket/d-5040253/kualif...\nPelatih bulutangkis ganda campuran Richard Mai...\n\n\n4\nPiala Thomas dan Uber 2020 Jadi Oktober, PBSI:...\n29 Apr 2020 22:25\nhttps://sport.detik.com/raket/d-4996515/piala-...\nPP PBSI merespons keputusan Badminton World Fe...\n\n\n5\nLiga Equestrian Digelar Akhir Pekan Ini, Ada 1...\n13 Des 2019 00:00\nhttps://sport.detik.com/sport-lain/d-4820926/l...\n\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r\"Equina...\n\n\n6\nBegini Cara Pegolf Lokal Cari Pengalaman\n17 Des 2017 22:50\nhttps://sport.detik.com/sport-lain/d-3773992/b...\n\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r\n\n\n7\nYang Perlu Diperbaiki Agar INASGOC Lebih Siap ...\n28 Nov 2017 13:55\nhttps://sport.detik.com/sport-lain/d-3746594/y...\n\\r\\r\\rSCROLL TO CONTINUE WITH CONTENT\\r\n\n\n8\nPembukaan Olimpiade Rio: Tampilkan Favela dan ...\n06 Agu 2016 11:20\nhttps://sport.detik.com/sport-lain/d-3269718/p...\nAwesome ðŸ˜? #OpeningCeremony #Rio2016 #olympi...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n%%capture\n!pip install nltk\n!pip install Sastrawi\n\n\nimport pandas as pd\nimport re\nimport nltk\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import RegexpTokenizer\n# tokenizer = RegexpTokenizer(r'\\w+')\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\nTrue\n\n\n\ndf = df.astype(str)\ndf[\"Content\"] = df[\"Content\"].apply(lambda x: x.lower())\n\ncontent_column = df[\"Content\"]\nkonten = pd.DataFrame(content_column, columns=['Content'])\nkonten\n\n\n  \n    \n\n\n\n\n\n\nContent\n\n\n\n\n0\nsekitar 8.000 peserta meriahkan ajang lari yan...\n\n\n1\nbrand apparel olahraga under armour mengadakan...\n\n\n2\npp pbsi menilai wajar keputusan badminton worl...\n\n\n3\npelatih bulutangkis ganda campuran richard mai...\n\n\n4\npp pbsi merespons keputusan badminton world fe...\n\n\n5\n\\r\\r\\rscroll to continue with content\\r\"equina...\n\n\n6\n\\r\\r\\rscroll to continue with content\\r\n\n\n7\n\\r\\r\\rscroll to continue with content\\r\n\n\n8\nawesome ðŸ˜? #openingceremony #rio2016 #olympi...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n5 Dokumen 1\n\nimport pandas as pd\n\n# Ambil satu dokumen dari baris pertama\ndokumen_pertama = df.at[0, 'Content']\n\n# Buat DataFrame dengan satu kolom dan satu baris\ndf_dokumen = pd.DataFrame({'Dokumen1': [dokumen_pertama]})\n\n# Tampilkan DataFrame\ndf_dokumen\n\n\n\n  \n    \n\n\n\n\n\n\nDokumen1\n\n\n\n\n0\nsekitar 8.000 peserta meriahkan ajang lari yan...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\n\n\n6 1. Ekstraksi Kalimat pada Berita 1\nPada proses ekstraksi kalimat dilakukan tokenisasi kalimat yang ada di dalam dokumen berita\n\nfrom nltk.tokenize import sent_tokenize\n\n# Misalnya, jika df adalah DataFrame yang memiliki kolom 'Content'\nteks_berita = df_dokumen['Dokumen1'].values.tolist()\n\nkalimat = []\nfor teks in teks_berita:\n    kalimat.extend(sent_tokenize(teks))\n\ndf_kalimat = pd.DataFrame(kalimat, columns=['Tokenisasi'])\ndf_kalimat\n\n\n  \n    \n\n\n\n\n\n\nTokenisasi\n\n\n\n\n0\nsekitar 8.000 peserta meriahkan ajang lari yan...\n\n\n1\npara peserta lomba lari ini tak hanya dari dal...\n\n\n2\nsemuanya terbuka untuk umum dan masyarakat.\n\n\n3\n\"pesertanya kita terbuka untuk semua.\n\n\n4\nmau yang sport enthusiast, professional runner...\n\n\n5\nscroll to continue with content\\rintan melanju...\n\n\n6\nkarena mencakup semua masyarakat, kegiatan ini...\n\n\n7\nharapannya yang bisa sehat bukan hanya individ...\n\n\n8\n\"kemudian kita ingin berkontribusi, terutama d...\n\n\n9\nsalah satunya adalah melalui kegiatan lazada run.\n\n\n10\n\"kita ingin menambahkan sehat dalam hidup mere...\n\n\n11\nkata intan.selain itu, deputi bidang produk wi...\n\n\n12\nmenurutnya kegiatan lazada bisa ikut mendorong...\n\n\n13\nsebab, baru pertama kali digelar kegiatan ini ...\n\n\n14\n\"ini baru pertama kali sudah 8.000. artinya apa?\n\n\n15\nkegiatan kedua, ketiga, nanti pasti akan naik,...\n\n\n16\n\"kami juga menantang lazada untuk menggelar ev...\n\n\n17\ntentunya kemenparekraf, khususnya bagian event...\n\n\n18\nkalau bisa suatu saat, maraton ini digelar di ...\n\n\n19\nsebelum berlari sesuai kategori, para peserta ...\n\n\n20\nbersama dengan 3 temannya, nunu telah datang s...\n\n\n21\n\"saya suka lari, hobi.\n\n\n22\nterus lazada run disponsori produk bagus.\n\n\n23\nkegiatan ini seru, larinya disemangatin,\" ungk...\n\n\n24\nbersama kedua temannya, dia mengikuti maraton ...\n\n\n25\njadi sekalian latihan nanti ada half marathon ...\n\n\n26\nmereka juga bahkan memiliki pelatih dan menjag...\n\n\n27\nselain itu, tata dan temannya berharap kegiata...\n\n\n28\nsetelah sebelumnya pertama kali digelar di vie...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n7 Menghilangkan Kata-kata dan Tanda baca tidak penting\n\nimport pandas as pd\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import stopwords\nimport string\n\n# Misalnya, jika df adalah DataFrame yang memiliki kolom 'Content'\nteks_berita = df_dokumen['Dokumen1'].values.tolist()\n\nkalimat = []\nfor teks in teks_berita:\n    # Tokenisasi\n    kalimat.extend(sent_tokenize(teks))\n\n# Membuang kata-kata atau tanda baca yang tidak penting\nstopwords_list = set(stopwords.words('english'))\ncleaned_sentences = []\n\nfor sentence in kalimat:\n    # Menghapus tanda baca\n    sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n\n    # Menghapus angka\n    sentence = ''.join([char for char in sentence if not char.isdigit()])\n\n    # Mengubah teks menjadi huruf kecil\n    sentence = sentence.lower()\n\n    # Membuang kata-kata yang merupakan stopwords\n    words = sentence.split()\n    words = [word for word in words if word not in stopwords_list]\n\n    # Menggabungkan kata-kata kembali menjadi kalimat\n    cleaned_sentence = \" \".join(words)\n\n    cleaned_sentences.append(cleaned_sentence)\n\n# Membuat DataFrame baru\ndf_cleaned1 = pd.DataFrame(cleaned_sentences, columns=['Tokenisasi Dokumen1'])\ndf_cleaned1\n\n\n  \n    \n\n\n\n\n\n\nTokenisasi Dokumen1\n\n\n\n\n0\nsekitar peserta meriahkan ajang lari yang dige...\n\n\n1\npara peserta lomba lari ini tak hanya dari dal...\n\n\n2\nsemuanya terbuka untuk umum dan masyarakat\n\n\n3\npesertanya kita terbuka untuk semua\n\n\n4\nmau yang sport enthusiast professional runners...\n\n\n5\nscroll continue content intan melanjutkan kegi...\n\n\n6\nkarena mencakup semua masyarakat kegiatan ini ...\n\n\n7\nharapannya yang bisa sehat bukan hanya individ...\n\n\n8\nkemudian kita ingin berkontribusi terutama dar...\n\n\n9\nsalah satunya adalah melalui kegiatan lazada run\n\n\n10\nkita ingin menambahkan sehat dalam hidup mereka\n\n\n11\nkata intanselain itu deputi bidang produk wisa...\n\n\n12\nmenurutnya kegiatan lazada bisa ikut mendorong...\n\n\n13\nsebab baru pertama kali digelar kegiatan ini s...\n\n\n14\nini baru pertama kali sudah artinya apa\n\n\n15\nkegiatan kedua ketiga nanti pasti akan naik uc...\n\n\n16\nkami juga menantang lazada untuk menggelar eve...\n\n\n17\ntentunya kemenparekraf khususnya bagian event ...\n\n\n18\nkalau bisa suatu saat maraton ini digelar di d...\n\n\n19\nsebelum berlari sesuai kategori para peserta j...\n\n\n20\nbersama dengan temannya nunu telah datang seja...\n\n\n21\nsaya suka lari hobi\n\n\n22\nterus lazada run disponsori produk bagus\n\n\n23\nkegiatan ini seru larinya disemangatin ungkap ...\n\n\n24\nbersama kedua temannya dia mengikuti maraton d...\n\n\n25\njadi sekalian latihan nanti ada half marathon ...\n\n\n26\nmereka juga bahkan memiliki pelatih dan menjag...\n\n\n27\nselain itu tata dan temannya berharap kegiatan...\n\n\n28\nsetelah sebelumnya pertama kali digelar di vie...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n8 2. Menghitung Nilai TF-IDF dari Dokumen Berita 1\nProses TF-IDF ini digunakan untuk mengetahui seberapa sering suatu kata muncul didalam dokumen. Berikut rumus perhitungan TF-IDF\n\\[\n\\begin{gathered}\nw_{i j}=t f_{i j} x i d f_j \\\\\nw_{i j}=t f_{i j} x \\log \\left(D / d f_j\\right)\n\\end{gathered}\n\\]\nDimana Wij merupakan bobot dari term(j) terhadapn dokumen(i). Sedangkan tfij merupakan jumlah kemunculan term(j) dalam dokumen(i). Untuk D sendiri merupakan jumlah semua dokumen yang ada pada data dan dfj merupakan jumlah dokumen yang mengandung term(j)\n\n\n9 Nilai Vektor kata antar Kalimat\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\n# Data kalimat (contoh)\nkalimat = df_cleaned1['Tokenisasi Dokumen1']\n\n# Membuat objek TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer()\n\n# Menghitung TF-IDF\ntfidf_matrix = tfidf_vectorizer.fit_transform(kalimat)\n\n# Mengonversi matriks TF-IDF ke DataFrame Pandas\ntfidf_kata1 = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Menampilkan tabel TF-IDF\ntfidf_kata1\n\n\n  \n    \n\n\n\n\n\n\nacaranya\nada\nadalah\naja\najang\nakan\nanakanak\nantusias\nantusiasme\napa\n...\nucap\nujar\numum\nungkap\nuntuk\nvietnam\nvinsensius\nvinsensiusmelihat\nwisata\nyang\n\n\n\n\n0\n0.000000\n0.00000\n0.000000\n0.00000\n0.29658\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.167853\n\n\n1\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.102965\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n2\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.493895\n0.00000\n0.266830\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n3\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.287165\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n4\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.229011\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.229011\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.259223\n\n\n5\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.175644\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n6\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n7\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.202226\n\n\n8\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.091132\n\n\n9\n0.000000\n0.00000\n0.429424\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n10\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n11\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.231301\n0.000000\n0.231301\n0.000000\n\n\n12\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n13\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n14\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.437311\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n15\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.176607\n0.000000\n0.176607\n0.00000\n0.000000\n...\n0.198289\n0.000000\n0.000000\n0.00000\n0.107127\n0.000000\n0.000000\n0.198289\n0.000000\n0.224448\n\n\n16\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.165951\n0.000000\n0.000000\n0.000000\n0.000000\n0.173847\n\n\n17\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.335657\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n18\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.18112\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.097851\n0.000000\n0.000000\n0.000000\n0.000000\n0.102507\n\n\n19\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.203517\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.123451\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n20\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.172220\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n21\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n22\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n23\n0.000000\n0.00000\n0.221011\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.24210\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.153841\n\n\n24\n0.295853\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25\n0.000000\n0.19434\n0.000000\n0.19434\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.17309\n0.209988\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n26\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n27\n0.000000\n0.00000\n0.165160\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.114964\n\n\n28\n0.000000\n0.00000\n0.000000\n0.00000\n0.00000\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.249031\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n29 rows × 249 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n10 Nilai Vektor antar Kata dengan Kata\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\n# Data kalimat (contoh)\nkalimat = df_cleaned1['Tokenisasi Dokumen1']\n\n# Membuat objek TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer()\n\n# Menghitung TF-IDF\ntfidf_matrix = tfidf_vectorizer.fit_transform(kalimat)\n\n# Mengonversi matriks TF-IDF ke DataFrame Pandas\ntfidf_kata1 = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Mengganti NaN dengan 0\ntfidf_kata1 = tfidf_kata1.fillna(0)\n\n# Menampilkan nilai TF-IDF dengan kata-kata\ntfidf_values_with_words = pd.concat([pd.Series(tfidf_vectorizer.get_feature_names_out(), name='Kata'),\n                                     tfidf_kata1], axis=1)\n\n# Menampilkan tabel TF-IDF dengan kata-kata\ntfidf_values_with_words\n\n\n\n  \n    \n\n\n\n\n\n\nKata\nacaranya\nada\nadalah\naja\najang\nakan\nanakanak\nantusias\nantusiasme\n...\nucap\nujar\numum\nungkap\nuntuk\nvietnam\nvinsensius\nvinsensiusmelihat\nwisata\nyang\n\n\n\n\n0\nacaranya\n0.0\n0.0\n0.0\n0.0\n0.29658\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.167853\n\n\n1\nada\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.000000\n0.0\n0.102965\n0.0\n0.0\n0.0\n0.0\n0.000000\n\n\n2\nadalah\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.493895\n0.0\n0.266830\n0.0\n0.0\n0.0\n0.0\n0.000000\n\n\n3\naja\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.000000\n0.0\n0.287165\n0.0\n0.0\n0.0\n0.0\n0.000000\n\n\n4\najang\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.229011\n0.0\n0.0\n...\n0.0\n0.229011\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.259223\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n244\nvietnam\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n245\nvinsensius\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n246\nvinsensiusmelihat\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n247\nwisata\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n248\nyang\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n249 rows × 250 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n11 Nilai Cosinus Similarity Kata Kunci\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Drop the 'Kata' column before calculating cosine similarity\ntfidf_vectors_only = tfidf_values_with_words.drop(columns=['Kata'])\n\n# Handling NaN values by filling them with 0\ntfidf_vectors_only = tfidf_vectors_only.fillna(0)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_vectors_only, tfidf_vectors_only)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df1 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_values_with_words.index, index=tfidf_values_with_words.index)\ncosine_sim_df1\n\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n\n\n\n\n0\n1.000000\n0.105866\n0.000000\n0.000000\n0.124813\n0.037802\n0.044076\n0.123862\n0.079240\n0.132162\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.105866\n1.000000\n0.060728\n0.029568\n0.010703\n0.071772\n0.103548\n0.145574\n0.153927\n0.158091\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.000000\n0.060728\n1.000000\n0.284872\n0.000000\n0.153018\n0.123767\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.000000\n0.029568\n0.284872\n1.000000\n0.000000\n0.050439\n0.159831\n0.000000\n0.113162\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n0.124813\n0.010703\n0.000000\n0.000000\n1.000000\n0.059062\n0.000000\n0.081330\n0.148080\n0.072391\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n244\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n245\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n246\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n247\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n248\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n249 rows × 249 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n12 Graph Kata Kunci\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Assuming tfidf_kata1 is your DataFrame with TF-IDF values\n# and top_keywords is the top keywords for each document\n\n# Handling NaN values by filling them with 0\ntfidf_kata1 = tfidf_kata1.fillna(0)\n\n# Calculate the sum of TF-IDF values for each term\nterm_sums = tfidf_kata1.sum()\n\n# Sort terms based on their sum of TF-IDF values in descending order\nsorted_terms = term_sums.sort_values(ascending=False)\n\n# Extract the top N keywords (adjust N as needed)\nN = 5\ntop_keywords = sorted_terms.head(N)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_kata1, tfidf_kata1)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df1 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_kata1.index, index=tfidf_kata1.index)\n\n# Creating a graph\nG = nx.Graph()\n\n# Adding nodes to the graph with top keywords as labels\nfor document in tfidf_kata1.index:\n    keywords_indices = tfidf_kata1.loc[document].values.argsort()[-N:][::-1]\n    keywords_list = tfidf_kata1.columns[keywords_indices].tolist()\n    G.add_node(document, label=\", \".join(map(str, keywords_list)))\n\n\n# Adding edges to the graph\nfor i in range(len(cosine_sim_df1.index)):\n    for j in range(i + 1, len(cosine_sim_df1.index)):\n        G.add_edge(cosine_sim_df1.index[i], cosine_sim_df1.index[j], weight=cosine_sim_df1.iloc[i, j])\n\n# Visualizing the graph\npos = nx.spring_layout(G)  # You can use different layouts depending on your preference\nedge_labels = nx.get_edge_attributes(G, 'weight')\n\nplt.figure(figsize=(12, 10))\nnx.draw(G, pos, with_labels=True, font_size=10, font_color=\"black\", node_size=800, node_color=\"skyblue\", font_weight=\"bold\", edge_color=\"gray\")\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color=\"red\", font_size=8)\nplt.title('Document Similarity Graph with Top Keywords')\nplt.show()\n\n\n\n\n\n\n13 Kata Kunci pada Dokumen 1\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Assuming tfidf_kata1 is your DataFrame with TF-IDF values\n# and top_keywords is the top keywords for each document\n\n# Handling NaN values by filling them with 0\ntfidf_kata1 = tfidf_kata1.fillna(0)\n\n# Calculate the sum of TF-IDF values for each term\nterm_sums = tfidf_kata1.sum()\n\n# Sort terms based on their sum of TF-IDF values in descending order\nsorted_terms = term_sums.sort_values(ascending=False)\n\n# Extract the top N keywords (adjust N as needed)\nN = 5\ntop_keywords = sorted_terms.head(N)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_kata1, tfidf_kata1)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df1 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_kata1.index, index=tfidf_kata1.index)\n\n# Creating a graph\nG = nx.Graph()\n\n# Adding nodes to the graph with top keywords as labels\nfor document in tfidf_kata1.index:\n    keywords_indices = tfidf_kata1.loc[document].values.argsort()[-N:][::-1]\n    keywords_list = tfidf_kata1.columns[keywords_indices].tolist()\n    G.add_node(document, label=\", \".join(map(str, keywords_list)))\n\n# Adding edges to the graph\nfor i in range(len(cosine_sim_df1.index)):\n    for j in range(i + 1, len(cosine_sim_df1.index)):\n        G.add_edge(cosine_sim_df1.index[i], cosine_sim_df1.index[j], weight=cosine_sim_df1.iloc[i, j])\n\n# Visualizing the graph\npos = nx.spring_layout(G)  # You can use different layouts depending on your preference\nedge_labels = nx.get_edge_attributes(G, 'weight')\nnode_labels = nx.get_node_attributes(G, 'label')\n\nplt.figure(figsize=(12, 10))\nnx.draw(G, pos, with_labels=True, font_size=10, font_color=\"black\", node_size=800, node_color=\"skyblue\", font_weight=\"bold\", edge_color=\"gray\")\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color=\"red\", font_size=8)\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8, font_color=\"green\")\n\n# Display top keywords for each node\nfor node, keywords in node_labels.items():\n    print(f\"Node {node} Keywords: {keywords}\")\n\nplt.title('Document Similarity Graph with Top Keywords')\nplt.show()\n\nNode 0 Keywords: tangerang, sekitar, kabupaten, ajang, bertajuk\nNode 1 Keywords: kota, luar, dari, ini, kenyachief\nNode 2 Keywords: umum, semuanya, terbuka, masyarakat, dan\nNode 3 Keywords: pesertanya, terbuka, semua, kita, untuk\nNode 4 Keywords: yang, community, mau, memang, mendapatkan\nNode 5 Keywords: scroll, content, melanjutkan, continue, pola\nNode 6 Keywords: karena, mencakup, ke, beberapa, semua\nNode 7 Keywords: harapannya, keluarga, individual, bukan, sehat\nNode 8 Keywords: ingin, berkontribusi, memberikan, dalam, kita\nNode 9 Keywords: melalui, adalah, satunya, salah, run\nNode 10 Keywords: menambahkan, mereka, sehat, dalam, hidup\nNode 11 Keywords: dan, berterima, pihaknya, mengapresiasi, deputi\nNode 12 Keywords: ikut, pariwisata, menurutnya, mendorong, bisa\nNode 13 Keywords: diikuti, sebab, hampir, baru, sudah\nNode 14 Keywords: apa, artinya, sudah, baru, kali\nNode 15 Keywords: kegiatan, yang, biasa, dilakukan, rutin\nNode 16 Keywords: event, menantang, kami, global, menggelar\nNode 17 Keywords: mendukung, siap, tentunya, khususnya, akan\nNode 18 Keywords: bisa, di, bajo, antusiasme, kawasan\nNode 19 Keywords: peserta, juga, serpong, berlari, diajak\nNode 20 Keywords: menyelesaikan, telah, berhasil, datang, sejak\nNode 21 Keywords: hobi, suka, saya, lari, yang\nNode 22 Keywords: bagus, disponsori, produk, terus, run\nNode 23 Keywords: ini, disemangatin, jakarta, nunuselain, larinya\nNode 24 Keywords: acaranya, banget, temanteman, banyak, kategoriini\nNode 25 Keywords: latihan, jadi, untuk, terbiasa, sih\nNode 26 Keywords: makan, gorengan, memiliki, pelatih, menjaga\nNode 27 Keywords: di, lazada, kegiatan, digelar, run\nNode 28 Keywords: pada, di, final, april, singapura\n\n\n\n\n\n\n\n14 3. Cosinuss Similarity pada Dokumen 1\nProses ini digunakan untuk mengukur jarak kedekatan antar dokumen dan diperoleh rumus sebagai berikut.\n\\[\n\\cos \\theta=\\frac{a \\cdot b}{\\|a\\| \\cdot\\|b\\|}\n\\]\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df1 = pd.DataFrame(cosine_sim_matrix, columns=df_cleaned1.index, index=df_cleaned1.index)\ncosine_sim_df1\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n\n0\n1.000000\n0.105866\n0.000000\n0.000000\n0.124813\n0.037802\n0.044076\n0.123862\n0.079240\n0.132162\n...\n0.053138\n0.000000\n0.078561\n0.122321\n0.057429\n0.043453\n0.028543\n0.000000\n0.261593\n0.143458\n\n\n1\n0.105866\n1.000000\n0.060728\n0.029568\n0.010703\n0.071772\n0.103548\n0.145574\n0.153927\n0.158091\n...\n0.243644\n0.121827\n0.050484\n0.022846\n0.184108\n0.045984\n0.083919\n0.130624\n0.128471\n0.022357\n\n\n2\n0.000000\n0.060728\n1.000000\n0.284872\n0.000000\n0.153018\n0.123767\n0.000000\n0.000000\n0.000000\n...\n0.032940\n0.101574\n0.000000\n0.000000\n0.000000\n0.000000\n0.056031\n0.046598\n0.035443\n0.000000\n\n\n3\n0.000000\n0.029568\n0.284872\n1.000000\n0.000000\n0.050439\n0.159831\n0.000000\n0.113162\n0.000000\n...\n0.035451\n0.049455\n0.000000\n0.000000\n0.000000\n0.000000\n0.060301\n0.000000\n0.000000\n0.000000\n\n\n4\n0.124813\n0.010703\n0.000000\n0.000000\n1.000000\n0.059062\n0.000000\n0.081330\n0.148080\n0.072391\n...\n0.000000\n0.000000\n0.000000\n0.067001\n0.039879\n0.000000\n0.000000\n0.000000\n0.146197\n0.164911\n\n\n5\n0.037802\n0.071772\n0.153018\n0.050439\n0.059062\n1.000000\n0.197093\n0.076796\n0.069215\n0.038778\n...\n0.062256\n0.030249\n0.000000\n0.000000\n0.096529\n0.000000\n0.071390\n0.068875\n0.096525\n0.050026\n\n\n6\n0.044076\n0.103548\n0.123767\n0.159831\n0.000000\n0.197093\n1.000000\n0.000000\n0.000000\n0.045213\n...\n0.096405\n0.068495\n0.000000\n0.000000\n0.112548\n0.000000\n0.040233\n0.000000\n0.112543\n0.058328\n\n\n7\n0.123862\n0.145574\n0.000000\n0.000000\n0.081330\n0.076796\n0.000000\n1.000000\n0.225818\n0.000000\n...\n0.052305\n0.000000\n0.000000\n0.000000\n0.031111\n0.033861\n0.022243\n0.030566\n0.164565\n0.062872\n\n\n8\n0.079240\n0.153927\n0.000000\n0.113162\n0.148080\n0.069215\n0.000000\n0.225818\n1.000000\n0.020855\n...\n0.065363\n0.000000\n0.000000\n0.019302\n0.035695\n0.030519\n0.020047\n0.055977\n0.090160\n0.038166\n\n\n9\n0.132162\n0.158091\n0.000000\n0.000000\n0.072391\n0.038778\n0.045213\n0.000000\n0.020855\n1.000000\n...\n0.027255\n0.000000\n0.000000\n0.154519\n0.222695\n0.000000\n0.023180\n0.155088\n0.345377\n0.108423\n\n\n10\n0.000000\n0.057750\n0.000000\n0.161062\n0.069394\n0.197027\n0.000000\n0.108271\n0.497674\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.080924\n0.000000\n0.000000\n\n\n11\n0.057880\n0.091010\n0.080717\n0.000000\n0.031703\n0.033965\n0.039602\n0.000000\n0.033755\n0.128292\n...\n0.058812\n0.052097\n0.000000\n0.157361\n0.056795\n0.000000\n0.020303\n0.043646\n0.195686\n0.060492\n\n\n12\n0.168602\n0.078189\n0.000000\n0.000000\n0.058194\n0.122424\n0.036346\n0.214717\n0.119969\n0.105630\n...\n0.021910\n0.000000\n0.000000\n0.050895\n0.052126\n0.000000\n0.018634\n0.000000\n0.262171\n0.124512\n\n\n13\n0.086432\n0.089147\n0.000000\n0.000000\n0.000000\n0.113368\n0.132182\n0.000000\n0.000000\n0.044331\n...\n0.112976\n0.000000\n0.000000\n0.000000\n0.149962\n0.000000\n0.039449\n0.000000\n0.110349\n0.179568\n\n\n14\n0.000000\n0.053393\n0.000000\n0.000000\n0.000000\n0.045540\n0.053098\n0.000000\n0.000000\n0.000000\n...\n0.032008\n0.000000\n0.000000\n0.000000\n0.076152\n0.000000\n0.027222\n0.000000\n0.000000\n0.143989\n\n\n15\n0.139192\n0.159860\n0.063183\n0.030763\n0.096497\n0.062492\n0.050924\n0.045389\n0.036114\n0.205231\n...\n0.177018\n0.040780\n0.000000\n0.081782\n0.218511\n0.085318\n0.104647\n0.041926\n0.250116\n0.075119\n\n\n16\n0.073862\n0.096634\n0.044281\n0.047655\n0.062316\n0.029148\n0.000000\n0.070313\n0.059658\n0.039784\n...\n0.065452\n0.028580\n0.000000\n0.036822\n0.026745\n0.029109\n0.053969\n0.026277\n0.085876\n0.018759\n\n\n17\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.088255\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n18\n0.182502\n0.092105\n0.057712\n0.028099\n0.088783\n0.059134\n0.048908\n0.176509\n0.044391\n0.000000\n...\n0.078283\n0.167017\n0.000000\n0.000000\n0.123539\n0.035424\n0.031822\n0.017088\n0.218502\n0.081422\n\n\n19\n0.053138\n0.243644\n0.032940\n0.035451\n0.000000\n0.062256\n0.096405\n0.052305\n0.065363\n0.027255\n...\n1.000000\n0.151993\n0.000000\n0.000000\n0.258785\n0.119950\n0.128969\n0.039094\n0.087493\n0.012851\n\n\n20\n0.000000\n0.121827\n0.101574\n0.049455\n0.000000\n0.030249\n0.068495\n0.000000\n0.000000\n0.000000\n...\n0.151993\n1.000000\n0.000000\n0.000000\n0.057283\n0.244078\n0.106397\n0.030076\n0.059581\n0.000000\n\n\n21\n0.078561\n0.050484\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.078369\n0.051479\n0.000000\n0.000000\n0.000000\n\n\n22\n0.122321\n0.022846\n0.000000\n0.000000\n0.067001\n0.000000\n0.000000\n0.000000\n0.019302\n0.154519\n...\n0.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.221975\n0.072858\n\n\n23\n0.057429\n0.184108\n0.000000\n0.000000\n0.039879\n0.096529\n0.112548\n0.031111\n0.035695\n0.222695\n...\n0.258785\n0.057283\n0.000000\n0.000000\n1.000000\n0.045586\n0.129551\n0.031828\n0.228314\n0.030574\n\n\n24\n0.043453\n0.045984\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.033861\n0.030519\n0.000000\n...\n0.119950\n0.244078\n0.078369\n0.000000\n0.045586\n1.000000\n0.182674\n0.025308\n0.053315\n0.000000\n\n\n25\n0.028543\n0.083919\n0.056031\n0.060301\n0.000000\n0.071390\n0.040233\n0.022243\n0.020047\n0.023180\n...\n0.128969\n0.106397\n0.051479\n0.000000\n0.129551\n0.182674\n1.000000\n0.016625\n0.061767\n0.010930\n\n\n26\n0.000000\n0.130624\n0.046598\n0.000000\n0.000000\n0.068875\n0.000000\n0.030566\n0.055977\n0.155088\n...\n0.039094\n0.030076\n0.000000\n0.000000\n0.031828\n0.025308\n0.016625\n1.000000\n0.060327\n0.000000\n\n\n27\n0.261593\n0.128471\n0.035443\n0.000000\n0.146197\n0.096525\n0.112543\n0.164565\n0.090160\n0.345377\n...\n0.087493\n0.059581\n0.000000\n0.221975\n0.228314\n0.053315\n0.061767\n0.060327\n1.000000\n0.254121\n\n\n28\n0.143458\n0.022357\n0.000000\n0.000000\n0.164911\n0.050026\n0.058328\n0.062872\n0.038166\n0.108423\n...\n0.012851\n0.000000\n0.000000\n0.072858\n0.030574\n0.000000\n0.010930\n0.000000\n0.254121\n1.000000\n\n\n\n\n\n29 rows × 29 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nKata Penting pada setiap Kalimat berdasarkan nilai TF-IDF pada Dokumen Berita 1\n\n# Menampilkan kata-kata dengan nilai TF-IDF tertinggi untuk setiap dokumen\nfor i, row in tfidf_kata1.iterrows():\n    print(f\"Kata-kata penting dalam Ringkasan Berita pada Kalimat {i + 1}:\")\n    top_keywords = row.sort_values(ascending=False).head(5)  # Ganti 5 dengan jumlah kata-kata penting yang diinginkan\n    print(top_keywords)\n    print(\"\\n\")\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 1:\najang        0.29658\ntangerang    0.29658\nbertajuk     0.29658\nkabupaten    0.29658\nmeriahkan    0.29658\nName: 0, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 2:\nkota       0.381169\nluar       0.339489\ndari       0.268237\nini        0.215727\nofficer    0.190584\nName: 1, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 3:\nsemuanya      0.493895\numum          0.493895\nterbuka       0.439889\nmasyarakat    0.401571\ndan           0.293559\nName: 2, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 4:\npesertanya    0.531533\nterbuka       0.473411\nsemua         0.473411\nkita          0.432173\nuntuk         0.287165\nName: 3, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 5:\nyang          0.259223\nenthusiast    0.229011\ncommunity     0.229011\nmemang        0.229011\nrunning       0.229011\nName: 4, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 6:\ncontent        0.325112\ncontinue       0.325112\nmelanjutkan    0.325112\nscroll         0.325112\npola           0.289562\nName: 5, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 7:\nke          0.379066\nbeberapa    0.379066\nmencakup    0.379066\nkarena      0.379066\nsemua       0.337616\nName: 6, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 8:\nharapannya    0.357314\nindividual    0.357314\nkeluarga      0.357314\nbukan         0.318243\ntetapi        0.290521\nName: 7, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 9:\ningin            0.392765\nmemberikan       0.322043\nberkontribusi    0.322043\ndalam            0.261843\nkita             0.261843\nName: 8, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 10:\nmelalui    0.528151\nadalah     0.429424\nsatunya    0.429424\nsalah      0.349716\nrun        0.313920\nName: 9, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 11:\nmenambahkan    0.408240\ningin          0.372679\nhidup          0.372679\nmereka         0.372679\ndalam          0.372679\nName: 10, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 12:\ndan            0.274960\njemadu         0.231301\nintanselain    0.231301\nwisata         0.231301\nvinsensius     0.231301\nName: 11, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 13:\nmenurutnya    0.424572\npariwisata    0.424572\nikut          0.424572\nmendorong     0.345207\nbisa          0.319657\nName: 12, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 14:\nhampir     0.371674\nsebab      0.371674\ndiikuti    0.371674\nsudah      0.331033\nbaru       0.331033\nName: 13, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 15:\napa        0.437311\nartinya    0.437311\nbaru       0.389492\nsudah      0.389492\nkali       0.355564\nName: 14, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 16:\nkegiatan      0.282693\nyang          0.224448\nucap          0.198289\nmenjadikan    0.198289\nketiga        0.198289\nName: 15, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 17:\nevent        0.547165\nglobal       0.307171\nmenantang    0.307171\nmenggelar    0.307171\nkami         0.307171\nName: 16, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 18:\nmendukung    0.376866\nkhususnya    0.376866\nsiap         0.376866\ntentunya     0.376866\nakan         0.335657\nName: 17, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 19:\nbisa       0.409091\ndi         0.215306\ndilihat    0.181120\nsaat       0.181120\nsuatu      0.181120\nName: 18, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 20:\npeserta      0.286150\njuga         0.258648\ndirinya      0.228503\nmelakukan    0.228503\nberlari      0.228503\nName: 19, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 21:\nberhasil         0.318774\ntelah            0.318774\nmenyelesaikan    0.318774\npagi             0.283917\ndatang           0.283917\nName: 20, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 22:\nsuka     0.534887\nsaya     0.534887\nhobi     0.534887\nlari     0.376412\npasti    0.000000\nName: 21, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 23:\nbagus         0.488822\ndisponsori    0.488822\nproduk        0.435370\nterus         0.435370\nrun           0.290543\nName: 22, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 24:\nini             0.307682\nlarinya         0.271823\njakarta         0.271823\ndisemangatin    0.271823\nseru            0.271823\nName: 23, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 25:\nacaranya       0.295853\nbanget         0.295853\nkategoriini    0.295853\ntemanteman     0.295853\nbanyak         0.295853\nName: 24, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 26:\njadi       0.388681\nlatihan    0.388681\nuntuk      0.209988\nhalf       0.194340\ntime       0.194340\nName: 25, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 27:\nmakan         0.534127\ntidak         0.267064\nmemiliki      0.267064\ngorengan      0.267064\ntersendiri    0.267064\nName: 26, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 28:\ndi          0.362208\nlazada      0.301775\nkegiatan    0.289596\ndigelar     0.254377\nrun         0.241472\nName: 27, dtype: float64\n\n\nKata-kata penting dalam Ringkasan Berita pada Kalimat 29:\npada         0.443601\ndi           0.296036\nbakal        0.249031\nsingapura    0.249031\nsetelah      0.249031\nName: 28, dtype: float64\n\n\n\n\n\n\n15 4. Graph Kata Penting berdasarkan nilai TF-IDF pada Dokumen 1\nGrap disini dibuat untuk menggambarkan nilai jarak antara kata satu dengan kata yang lain berdasarkan nilai Cosinuss Similarity dari Dokumen berita 1\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Membuat grafik jaringan\nG = nx.Graph()\n\n# Menambahkan simpul (kalimat)\nfor i in range(len(cosine_sim_matrix)):\n    G.add_node(i, label=df_cleaned1.index[i])  # Menggunakan label kalimat\n\n# Menambahkan tepian (hubungan) berdasarkan kesamaan kosinus\nfor i in range(len(cosine_sim_matrix)):\n    for j in range(i+1, len(cosine_sim_matrix)):\n        similarity = cosine_sim_matrix[i][j]\n        if similarity &gt; 0.1:  # Atur threshold sesuai kebutuhan\n            G.add_edge(i, j, weight=similarity)\n\n# Menggambar grafik jaringan\npos = nx.spring_layout(G, seed=42)  # Menggunakan layout spring\nlabels = nx.get_node_attributes(G, 'label')\n\nnx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500, font_size=8, font_color='black')\nnx.draw_networkx_edge_labels(G, pos, edge_labels={(i, j): f\"{similarity:.2f}\" for i, j, similarity in G.edges(data='weight')})\n\nplt.show()\n\n\n\n\n\n\n16 5. Closeness Centrality Dokumen Berita 1\nPada proses ini Closeness Centrality digunakan untuk menghitung bobot sebuah node berdasarkan jumlah jarak terpendek antara node(i) dengan node lainnya. Berikut rumus Closeness Centrality\n\\[\nC_c(i)=\\frac{n-1}{\\sum_{j=1}^n d(i, j)}\n\\]\n\nimport networkx as nx\n\ncloseness_centrality = nx.closeness_centrality(G)\n\nsorted_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)\n\nfor node, closeness in sorted_closeness:\n    print(f\"Simpul {node}: Closeness Centrality = {closeness:.4f}\")\n\nSimpul 27: Closeness Centrality = 0.6199\nSimpul 1: Closeness Centrality = 0.5786\nSimpul 23: Closeness Centrality = 0.5540\nSimpul 0: Closeness Centrality = 0.5424\nSimpul 9: Closeness Centrality = 0.5313\nSimpul 15: Closeness Centrality = 0.5313\nSimpul 18: Closeness Centrality = 0.5313\nSimpul 12: Closeness Centrality = 0.5207\nSimpul 6: Closeness Centrality = 0.5105\nSimpul 7: Closeness Centrality = 0.5007\nSimpul 13: Closeness Centrality = 0.5007\nSimpul 19: Closeness Centrality = 0.4912\nSimpul 20: Closeness Centrality = 0.4734\nSimpul 28: Closeness Centrality = 0.4649\nSimpul 8: Closeness Centrality = 0.4568\nSimpul 5: Closeness Centrality = 0.4413\nSimpul 11: Closeness Centrality = 0.4413\nSimpul 4: Closeness Centrality = 0.4268\nSimpul 25: Closeness Centrality = 0.4199\nSimpul 2: Closeness Centrality = 0.4133\nSimpul 22: Closeness Centrality = 0.4068\nSimpul 26: Closeness Centrality = 0.4005\nSimpul 16: Closeness Centrality = 0.3945\nSimpul 3: Closeness Centrality = 0.3886\nSimpul 10: Closeness Centrality = 0.3886\nSimpul 14: Closeness Centrality = 0.3667\nSimpul 24: Closeness Centrality = 0.3567\nSimpul 17: Closeness Centrality = 0.2830\nSimpul 21: Closeness Centrality = 0.0000\n\n\n\n\n17 6. PageRank Dokumen 1\nPagerank merupakan suatu proses mengukur atau mencari nilai penting dalam suatu dokumen\n\\[\n\\operatorname{PR}\\left(S_i\\right)=\\frac{1-\\alpha}{\\text { NodeCount }}+\\alpha \\sum_{S_j} \\in \\text { Neighbors } S_i \\frac{\\operatorname{PR}\\left(S_j\\right)}{\\operatorname{CountEdge}\\left(S_j\\right)}\n\\]\nKeterangan: \\[\n\\begin{array}{ll}\nP R\\left(S_i\\right) & \\text { : Nilai PageRank untuk kaliamt } \\mathrm{Si} \\\\\n\\operatorname{PR}\\left(S_j\\right) & \\text { : Nilai PageRank dari vertex yang bertetangga dengan } \\mathrm{Si} \\\\\n\\text { CountEdge }\\left(S_j\\right) & \\text { : Jumlah edge dari kalimat } \\mathrm{Sj} \\\\\n\\alpha_i  & \\text { : Damping faktor yang nilainya antara 0 dan 1 } \\\\\n\\end{array}\n\\]\n\nG = nx.DiGraph(nx.path_graph(4))\npr = nx.pagerank(G, alpha=0.9)\npr\n\n{0: 0.1724140124772394,\n 1: 0.3275859875227606,\n 2: 0.3275859875227606,\n 3: 0.1724140124772394}\n\n\n\n\n18 7. EIgenVector dari Dokumen Berita 1\nEigenVector digunakan untuk menghitung sentralitas sebuah node dengan menambahkan sentralitas pendahulunya. Berikut nilai persamaan dari EigenVector\n\\[\n\\lambda x_i=\\sum_{j \\rightarrow i} x_j\n\\]\n\nG = nx.path_graph(4)\ncentrality = nx.eigenvector_centrality(G)\nsorted((v, f\"{c:0.2f}\") for v, c in centrality.items())\n\n[(0, '0.37'), (1, '0.60'), (2, '0.60'), (3, '0.37')]\n\n\nTampilan Kalimat penting berdasarkan nilai EigenVector pada Dokumen Berita 1\n\nimport networkx as nx\n\n# Membuat grafik jaringan (contoh: grafik jalur)\nG = nx.path_graph(4)\n\n# Menghitung eigenvector centrality\ncentrality = nx.eigenvector_centrality(G)\n\n# Data berita (dalam bentuk daftar)\nberita =df_cleaned1['Tokenisasi Dokumen1']\n\n# Menampilkan kalimat dari eigenvector centrality dan mengaitkannya dengan dokumen berita\nfor node, centrality_score in centrality.items():\n    if 0 &lt;= node &lt; len(berita):\n        kalimat = f\"Kalimat berita1: '{berita[node]}' memiliki Eigenvector Centrality sebesar {centrality_score:.2f}\"\n        print(kalimat)\n\nKalimat berita1: 'sekitar peserta meriahkan ajang lari yang digelar lazada indonesia bertajuk lazada run di ice bsd kabupaten tangerang' memiliki Eigenvector Centrality sebesar 0.37\nKalimat berita1: 'para peserta lomba lari ini tak hanya dari dalam kota tetapi juga datang dari luar kota bahkan luar negara salah satunya kenyachief marketing officer lazada indonesia mengatakan untuk kategori kegiatan ini dibagi menjadi k k dan k' memiliki Eigenvector Centrality sebesar 0.60\nKalimat berita1: 'semuanya terbuka untuk umum dan masyarakat' memiliki Eigenvector Centrality sebesar 0.60\nKalimat berita1: 'pesertanya kita terbuka untuk semua' memiliki Eigenvector Centrality sebesar 0.37\n\n\n\n\n19 8. Mencari Kata Kunci\nNilai TF-IDF Kata Kunci Dokumen 1\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\n# Data kalimat (contoh)\nkalimat = df_cleaned1['Tokenisasi Dokumen1']\n\n# Membuat objek TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer()\n\n# Menghitung TF-IDF\ntfidf_matrix = tfidf_vectorizer.fit_transform(kalimat)\n\n# Mengonversi matriks TF-IDF ke DataFrame Pandas\ntfidf_kata1 = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Mengganti NaN dengan 0\ntfidf_kata1 = tfidf_kata1.fillna(0)\n\n# Menampilkan nilai TF-IDF dengan kata-kata\ntfidf_values_with_words = pd.concat([pd.Series(tfidf_vectorizer.get_feature_names_out(), name='Kata'),\n                                     tfidf_kata1], axis=1)\n\n# Menampilkan tabel TF-IDF dengan kata-kata\ntfidf_values_with_words\n\n\n  \n    \n\n\n\n\n\n\nKata\nacaranya\nada\nadalah\naja\najang\nakan\nanakanak\nantusias\nantusiasme\n...\nucap\nujar\numum\nungkap\nuntuk\nvietnam\nvinsensius\nvinsensiusmelihat\nwisata\nyang\n\n\n\n\n0\nacaranya\n0.0\n0.0\n0.0\n0.0\n0.29658\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.167853\n\n\n1\nada\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.000000\n0.0\n0.102965\n0.0\n0.0\n0.0\n0.0\n0.000000\n\n\n2\nadalah\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.493895\n0.0\n0.266830\n0.0\n0.0\n0.0\n0.0\n0.000000\n\n\n3\naja\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.000000\n0.0\n0.0\n...\n0.0\n0.000000\n0.000000\n0.0\n0.287165\n0.0\n0.0\n0.0\n0.0\n0.000000\n\n\n4\najang\n0.0\n0.0\n0.0\n0.0\n0.00000\n0.0\n0.229011\n0.0\n0.0\n...\n0.0\n0.229011\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.259223\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n244\nvietnam\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n245\nvinsensius\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n246\nvinsensiusmelihat\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n247\nwisata\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n248\nyang\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n249 rows × 250 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nNilai Cosinus Similarity Kata Kunci Dokumen 1\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Drop the 'Kata' column before calculating cosine similarity\ntfidf_vectors_only = tfidf_values_with_words.drop(columns=['Kata'])\n\n# Handling NaN values by filling them with 0\ntfidf_vectors_only = tfidf_vectors_only.fillna(0)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_vectors_only, tfidf_vectors_only)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df1 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_values_with_words.index, index=tfidf_values_with_words.index)\ncosine_sim_df1\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n\n\n\n\n0\n1.000000\n0.105866\n0.000000\n0.000000\n0.124813\n0.037802\n0.044076\n0.123862\n0.079240\n0.132162\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.105866\n1.000000\n0.060728\n0.029568\n0.010703\n0.071772\n0.103548\n0.145574\n0.153927\n0.158091\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.000000\n0.060728\n1.000000\n0.284872\n0.000000\n0.153018\n0.123767\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.000000\n0.029568\n0.284872\n1.000000\n0.000000\n0.050439\n0.159831\n0.000000\n0.113162\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n0.124813\n0.010703\n0.000000\n0.000000\n1.000000\n0.059062\n0.000000\n0.081330\n0.148080\n0.072391\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n244\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n245\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n246\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n247\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n248\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n249 rows × 249 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nGraph Dan Kata Kunci pada Dokumen 1\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Assuming tfidf_kata1 is your DataFrame with TF-IDF values\n# and top_keywords is the top keywords for each document\n\n# Handling NaN values by filling them with 0\ntfidf_kata1 = tfidf_kata1.fillna(0)\n\n# Calculate the sum of TF-IDF values for each term\nterm_sums = tfidf_kata1.sum()\n\n# Sort terms based on their sum of TF-IDF values in descending order\nsorted_terms = term_sums.sort_values(ascending=False)\n\n# Extract the top N keywords (adjust N as needed)\nN = 1\ntop_keywords = sorted_terms.head(N)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_kata1, tfidf_kata1)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df1 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_kata1.index, index=tfidf_kata1.index)\n\n# Create a list of nodes sorted by the highest TF-IDF value\nsorted_nodes = sorted(tfidf_kata1.index, key=lambda x: tfidf_kata1.loc[x].max(), reverse=True)\n\n# Creating a graph\nG = nx.Graph()\n\n# Adding nodes to the graph with top keywords as labels\nfor document in sorted_nodes:\n    keywords_indices = tfidf_kata1.loc[document].values.argsort()[-N:][::-1]\n    keywords_list = tfidf_kata1.columns[keywords_indices].tolist()\n    keywords_values = tfidf_kata1.loc[document, keywords_list].tolist()\n\n    # Sorting keywords and values in descending order\n    sorted_keywords_values = sorted(zip(keywords_list, keywords_values), key=lambda x: x[1], reverse=True)\n\n    node_label = \", \".join([f\"{kw} ({val:.4f})\" for kw, val in sorted_keywords_values])\n    G.add_node(document, label=node_label)\n\n# Adding edges to the graph\nfor i in range(len(cosine_sim_df1.index)):\n    for j in range(i + 1, len(cosine_sim_df1.index)):\n        G.add_edge(cosine_sim_df1.index[i], cosine_sim_df1.index[j], weight=cosine_sim_df1.iloc[i, j])\n\n# Visualizing the graph\npos = nx.spring_layout(G)  # You can use different layouts depending on your preference\nedge_labels = nx.get_edge_attributes(G, 'weight')\nnode_labels = nx.get_node_attributes(G, 'label')\n\nplt.figure(figsize=(12, 10))\nnx.draw(G, pos, with_labels=True, font_size=10, font_color=\"black\", node_size=800, node_color=\"skyblue\", font_weight=\"bold\", edge_color=\"gray\")\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color=\"red\", font_size=8)\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8, font_color=\"green\")\n\n# Display top keywords and values for each node\nfor node, label in node_labels.items():\n    print(f\"Node {node} Keywords and Values: {label}\")\n\nplt.title('Document Similarity Graph with Top Keywords and Values (Sorted)')\nplt.show()\n\n\nNode 16 Keywords and Values: event (0.5472)\nNode 21 Keywords and Values: hobi (0.5349)\nNode 26 Keywords and Values: makan (0.5341)\nNode 3 Keywords and Values: pesertanya (0.5315)\nNode 9 Keywords and Values: melalui (0.5282)\nNode 2 Keywords and Values: umum (0.4939)\nNode 22 Keywords and Values: bagus (0.4888)\nNode 28 Keywords and Values: pada (0.4436)\nNode 14 Keywords and Values: apa (0.4373)\nNode 12 Keywords and Values: ikut (0.4246)\nNode 18 Keywords and Values: bisa (0.4091)\nNode 10 Keywords and Values: menambahkan (0.4082)\nNode 8 Keywords and Values: ingin (0.3928)\nNode 25 Keywords and Values: latihan (0.3887)\nNode 1 Keywords and Values: kota (0.3812)\nNode 6 Keywords and Values: karena (0.3791)\nNode 17 Keywords and Values: mendukung (0.3769)\nNode 13 Keywords and Values: diikuti (0.3717)\nNode 27 Keywords and Values: di (0.3622)\nNode 7 Keywords and Values: harapannya (0.3573)\nNode 5 Keywords and Values: scroll (0.3251)\nNode 20 Keywords and Values: menyelesaikan (0.3188)\nNode 23 Keywords and Values: ini (0.3077)\nNode 0 Keywords and Values: tangerang (0.2966)\nNode 24 Keywords and Values: acaranya (0.2959)\nNode 19 Keywords and Values: peserta (0.2861)\nNode 15 Keywords and Values: kegiatan (0.2827)\nNode 11 Keywords and Values: dan (0.2750)\nNode 4 Keywords and Values: yang (0.2592)\n\n\n\n\n\n\n\n20 Dokumen 2\n\nimport pandas as pd\n\n# Ambil satu dokumen dari baris pertama\ndokumen_pertama = df.at[1, 'Content']\n\n# Buat DataFrame dengan satu kolom dan satu baris\ndf_dokumen2 = pd.DataFrame({'Dokumen2': [dokumen_pertama]})\n\n# Tampilkan DataFrame\ndf_dokumen2\n\n\n  \n    \n\n\n\n\n\n\nDokumen2\n\n\n\n\n0\nbrand apparel olahraga under armour mengadakan...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\n\n\n21 1. Ekstraksi Kalimat pada Dokumen Berita 2\n\nfrom nltk.tokenize import sent_tokenize\n\n# Misalnya, jika df adalah DataFrame yang memiliki kolom 'Content'\nteks_berita = df_dokumen2['Dokumen2'].values.tolist()\n\nkalimat = []\nfor teks in teks_berita:\n    kalimat.extend(sent_tokenize(teks))\n\ndf_kalimat2 = pd.DataFrame(kalimat, columns=['Tokenisasi'])\ndf_kalimat2\n\n\n  \n    \n\n\n\n\n\n\nTokenisasi\n\n\n\n\n0\nbrand apparel olahraga under armour mengadakan...\n\n\n1\nkegiatan yang diadakan di senayan, jakarta, in...\n\n\n2\nunder armour juga mengundang 11 komunitas lari.\n\n\n3\n\"kita undang komunitas lari.\n\n\n4\nsebenarnya kita cuma memberikan slot (peserta)...\n\n\n5\ntapi ini acaranya super sukses karena ramai ba...\n\n\n6\nintinya kita undang semua masyarakat untuk iku...\n\n\n7\nsekaligus sebagai pemanasan menghadapi challen...\n\n\n8\ndikatakannya, selama fun run 4k berlangsung pe...\n\n\n9\nscroll to continue with content\\r\"kita menduku...\n\n\n10\nuntuk membantu mempersiapkan diri juga sebelum...\n\n\n11\nadapun proses pendaftarannya sudah dibuka seja...\n\n\n12\nagenda ini dikuti 400 peserta dari eropa, amer...\n\n\n13\nselama periode itu, peserta individu maupun se...\n\n\n14\nhasil data berlari peserta secara otomatis aka...\n\n\n15\nmengingat jaraknya yang hanya 1 mil atau 1,6 k...\n\n\n16\n\"kita juga mengajak masyarakat kembali ke real...\n\n\n17\njadi semacam reuni lagi.\n\n\n18\napalagi sudah berapa tahun kita (dilanda) pand...\n\n\n19\njadi rasanya ini waktu yang tepat untuk mendap...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n22 Menghilangkan Kata dan Tanda tidak penting pada Dokumen 2\n\nimport pandas as pd\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import stopwords\nimport string\n\n# Misalnya, jika df adalah DataFrame yang memiliki kolom 'Content'\nteks_berita = df_dokumen2['Dokumen2'].values.tolist()\n\nkalimat = []\nfor teks in teks_berita:\n    # Tokenisasi\n    kalimat.extend(sent_tokenize(teks))\n\n# Membuang kata-kata atau tanda baca yang tidak penting\nstopwords_list = set(stopwords.words('english'))\ncleaned_sentences = []\n\nfor sentence in kalimat:\n    # Menghapus tanda baca\n    sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n\n    # Menghapus angka\n    sentence = ''.join([char for char in sentence if not char.isdigit()])\n\n    # Mengubah teks menjadi huruf kecil\n    sentence = sentence.lower()\n\n    # Membuang kata-kata yang merupakan stopwords\n    words = sentence.split()\n    words = [word for word in words if word not in stopwords_list]\n\n    # Menggabungkan kata-kata kembali menjadi kalimat\n    cleaned_sentence = \" \".join(words)\n\n    cleaned_sentences.append(cleaned_sentence)\n\n# Membuat DataFrame baru\ndf_cleaned2 = pd.DataFrame(cleaned_sentences, columns=['Tokenisasi Dokumen2'])\ndf_cleaned2\n\n\n  \n    \n\n\n\n\n\n\nTokenisasi Dokumen2\n\n\n\n\n0\nbrand apparel olahraga armour mengadakan kompe...\n\n\n1\nkegiatan yang diadakan di senayan jakarta ini ...\n\n\n2\narmour juga mengundang komunitas lari\n\n\n3\nkita undang komunitas lari\n\n\n4\nsebenarnya kita cuma memberikan slot peserta t...\n\n\n5\ntapi ini acaranya super sukses karena ramai ba...\n\n\n6\nintinya kita undang semua masyarakat untuk iku...\n\n\n7\nsekaligus sebagai pemanasan menghadapi challen...\n\n\n8\ndikatakannya selama fun run k berlangsung pese...\n\n\n9\nscroll continue content kita mendukung semua o...\n\n\n10\nuntuk membantu mempersiapkan diri juga sebelum...\n\n\n11\nadapun proses pendaftarannya sudah dibuka seja...\n\n\n12\nagenda ini dikuti peserta dari eropa amerika s...\n\n\n13\nselama periode itu peserta individu maupun sec...\n\n\n14\nhasil data berlari peserta secara otomatis aka...\n\n\n15\nmengingat jaraknya yang hanya mil atau km maka...\n\n\n16\nkita juga mengajak masyarakat kembali ke reali...\n\n\n17\njadi semacam reuni lagi\n\n\n18\napalagi sudah berapa tahun kita dilanda pandemi\n\n\n19\njadi rasanya ini waktu yang tepat untuk mendap...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n23 2. TF-IDF\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\n# Data kalimat (contoh)\nkalimat = df_cleaned2['Tokenisasi Dokumen2']\n\n# Membuat objek TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer()\n\n# Menghitung TF-IDF\ntfidf_matrix = tfidf_vectorizer.fit_transform(kalimat)\n\n# Mengonversi matriks TF-IDF ke DataFrame Pandas\ntfidf_kata2 = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Menampilkan tabel TF-IDF\ntfidf_kata2\n\n\n  \n    \n\n\n\n\n\n\nacaranya\nadapun\nade\nagenda\najang\nakan\namerika\nanakanak\napalagi\naplikasi\n...\nujar\nundang\nuntuk\nurutanranking\nutama\nvideo\nwaktu\nwindow\nyaitu\nyang\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n1\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.289316\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.169640\n\n\n2\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n3\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.568672\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n4\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n5\n0.369011\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n6\n0.000000\n0.000000\n0.356671\n0.000000\n0.178336\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.178336\n0.156760\n0.223345\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n7\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.237086\n\n\n8\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.141210\n\n\n9\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.203755\n\n\n10\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.131137\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.122793\n\n\n11\n0.000000\n0.233685\n0.000000\n0.000000\n0.000000\n0.205412\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.233685\n0.000000\n0.000000\n\n\n12\n0.000000\n0.000000\n0.000000\n0.320139\n0.000000\n0.000000\n0.320139\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n13\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.183375\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n14\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.263623\n0.000000\n0.000000\n0.000000\n0.149954\n...\n0.000000\n0.000000\n0.093900\n0.149954\n0.149954\n0.000000\n0.000000\n0.000000\n0.149954\n0.000000\n\n\n15\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.185230\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.173444\n\n\n16\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n17\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n18\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.429416\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n19\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.125195\n0.000000\n0.000000\n0.199931\n0.199931\n0.000000\n0.000000\n0.117229\n\n\n\n\n\n20 rows × 207 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Menampilkan kata-kata dengan nilai TF-IDF tertinggi untuk setiap dokumen\nfor i, row in tfidf_kata2.iterrows():\n    print(f\"Kata-kata penting dalam Dokumen Berita 2 pada Kalimat {i + 1}:\")\n    top_keywords = row.sort_values(ascending=False).head(5)  # Ganti 5 dengan jumlah kata-kata penting yang diinginkan\n    print(top_keywords)\n    print(\"\\n\")\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 1:\nlari        0.404653\nolahraga    0.300996\nrangkap     0.300996\nbrand       0.300996\nsedunia     0.300996\nName: 0, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 2:\nsenayan     0.289316\njakarta     0.289316\ndewasa      0.289316\nanakanak    0.289316\nsebanyak    0.289316\nName: 1, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 3:\nmengundang    0.543802\nkomunitas     0.478010\njuga          0.431330\narmour        0.395122\nlari          0.365538\nName: 2, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 4:\nkomunitas    0.568672\nundang       0.568672\nlari         0.434868\nkita         0.405111\nacaranya     0.000000\nName: 3, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 5:\ncuma          0.415793\nmemberikan    0.415793\nslot          0.415793\nsebenarnya    0.415793\nterbatas      0.415793\nName: 4, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 6:\nacaranya    0.369011\nbanget      0.369011\nsukses      0.369011\nsuper       0.369011\ntapi        0.369011\nName: 5, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 7:\nade          0.356671\nuntuk        0.223345\nini          0.209134\nmarketing    0.178336\nditemui      0.178336\nName: 6, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 8:\nsesungguhnya    0.404343\nmenghadapi      0.404343\nsebagai         0.404343\npemanasan       0.404343\nsekaligus       0.404343\nName: 7, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 9:\nmemilih     0.240828\ngrup        0.240828\nsesuai      0.240828\nbeberapa    0.240828\ndengan      0.240828\nName: 8, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 10:\ncontent            0.347498\ncontinue           0.347498\nscroll             0.347498\nbersenangsenang    0.347498\nmendukung          0.347498\nName: 9, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 11:\nnegara           0.209419\nbelum            0.209419\nmembantu         0.209419\nbersamaan        0.209419\nmempersiapkan    0.209419\nName: 10, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 12:\nmei            0.233685\nmendatang      0.233685\ncompetition    0.233685\nsejak          0.233685\ndibuka         0.233685\nName: 11, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 13:\nserikat    0.320139\namerika    0.320139\nasia       0.320139\ndikuti     0.320139\nsouth      0.320139\nName: 12, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 14:\nsejauh       0.29284\nitu          0.29284\nmaupun       0.29284\nditantang    0.29284\nperiode      0.29284\nName: 13, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 15:\nakan       0.263623\nberlari    0.263623\ndalam      0.237879\ndi         0.217911\npeserta    0.187800\nName: 14, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 16:\nmengingat    0.295803\npemula       0.295803\ncocok        0.295803\njaraknya     0.295803\nhanya        0.295803\nName: 15, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 17:\nrealita    0.385156\nback       0.385156\nkembali    0.338558\nrun        0.338558\nke         0.338558\nName: 16, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 18:\nreuni      0.531094\nsemacam    0.531094\njadi       0.466840\nlagi       0.466840\npara       0.000000\nName: 17, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 19:\ndilanda    0.429416\napalagi    0.429416\nberapa     0.429416\ntahun      0.377464\nsudah      0.340602\nName: 18, dtype: float64\n\n\nKata-kata penting dalam Dokumen Berita 2 pada Kalimat 20:\nrunning                0.351484\njogging                0.199931\nselengkapnyahalaman    0.199931\nselanjutnya            0.199931\ndetikolahraga          0.199931\nName: 19, dtype: float64\n\n\n\n\n\n\n24 3. Cosinuss Similarity\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix2 = cosine_similarity(tfidf_matrix, tfidf_matrix)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df2 = pd.DataFrame(cosine_sim_matrix2, columns=df_cleaned2.index, index=df_cleaned2.index)\ncosine_sim_df2\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n\n0\n1.000000\n0.000000\n0.234330\n0.175971\n0.000000\n0.000000\n0.028339\n0.000000\n0.045604\n0.000000\n0.138945\n0.054348\n0.000000\n0.000000\n0.080621\n0.000000\n0.000000\n0.000000\n0.000000\n0.117923\n\n\n1\n0.000000\n1.000000\n0.000000\n0.000000\n0.047170\n0.036705\n0.095177\n0.040219\n0.051276\n0.112246\n0.076575\n0.101994\n0.104481\n0.033222\n0.096843\n0.178812\n0.000000\n0.000000\n0.000000\n0.062455\n\n\n2\n0.234330\n0.000000\n1.000000\n0.430792\n0.000000\n0.000000\n0.051199\n0.000000\n0.000000\n0.000000\n0.123103\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.131770\n0.000000\n0.000000\n0.106524\n\n\n3\n0.175971\n0.000000\n0.430792\n1.000000\n0.105478\n0.000000\n0.134385\n0.000000\n0.000000\n0.088153\n0.061216\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.097706\n0.000000\n0.108934\n0.058443\n\n\n4\n0.000000\n0.047170\n0.000000\n0.105478\n1.000000\n0.000000\n0.029076\n0.000000\n0.039265\n0.056656\n0.000000\n0.000000\n0.052196\n0.047745\n0.048897\n0.000000\n0.062796\n0.000000\n0.070012\n0.000000\n\n\n5\n0.000000\n0.036705\n0.000000\n0.000000\n0.000000\n1.000000\n0.045250\n0.000000\n0.000000\n0.000000\n0.000000\n0.029647\n0.040616\n0.000000\n0.000000\n0.037528\n0.000000\n0.000000\n0.000000\n0.025365\n\n\n6\n0.028339\n0.095177\n0.051199\n0.134385\n0.029076\n0.045250\n1.000000\n0.000000\n0.022674\n0.072183\n0.178788\n0.028656\n0.039257\n0.068527\n0.082857\n0.110831\n0.070146\n0.000000\n0.030029\n0.126400\n\n\n7\n0.000000\n0.040219\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n0.033479\n0.048308\n0.094540\n0.000000\n0.000000\n0.000000\n0.000000\n0.041121\n0.000000\n0.000000\n0.000000\n0.027794\n\n\n8\n0.045604\n0.051276\n0.000000\n0.000000\n0.039265\n0.000000\n0.022674\n0.033479\n1.000000\n0.028772\n0.075695\n0.035406\n0.078736\n0.119378\n0.124384\n0.024492\n0.143340\n0.000000\n0.000000\n0.016554\n\n\n9\n0.000000\n0.112246\n0.000000\n0.088153\n0.056656\n0.000000\n0.072183\n0.048308\n0.028772\n1.000000\n0.025020\n0.000000\n0.000000\n0.000000\n0.000000\n0.035340\n0.052482\n0.000000\n0.058512\n0.023886\n\n\n10\n0.138945\n0.076575\n0.123103\n0.061216\n0.000000\n0.000000\n0.178788\n0.094540\n0.075695\n0.025020\n1.000000\n0.080766\n0.026289\n0.133587\n0.113877\n0.084560\n0.050745\n0.000000\n0.056576\n0.088253\n\n\n11\n0.054348\n0.101994\n0.000000\n0.000000\n0.000000\n0.029647\n0.028656\n0.000000\n0.035406\n0.000000\n0.080766\n1.000000\n0.055056\n0.000000\n0.067892\n0.023766\n0.000000\n0.000000\n0.063132\n0.034383\n\n\n12\n0.000000\n0.104481\n0.000000\n0.000000\n0.052196\n0.040616\n0.039257\n0.000000\n0.078736\n0.000000\n0.026289\n0.055056\n1.000000\n0.036761\n0.086674\n0.032558\n0.000000\n0.000000\n0.000000\n0.047103\n\n\n13\n0.000000\n0.033222\n0.000000\n0.000000\n0.047745\n0.000000\n0.068527\n0.000000\n0.119378\n0.000000\n0.133587\n0.000000\n0.036761\n1.000000\n0.147143\n0.222325\n0.000000\n0.000000\n0.000000\n0.022958\n\n\n14\n0.080621\n0.096843\n0.000000\n0.000000\n0.048897\n0.000000\n0.082857\n0.000000\n0.124384\n0.000000\n0.113877\n0.067892\n0.086674\n0.147143\n1.000000\n0.051666\n0.125587\n0.000000\n0.090265\n0.081366\n\n\n15\n0.000000\n0.178812\n0.000000\n0.000000\n0.000000\n0.037528\n0.110831\n0.041121\n0.024492\n0.035340\n0.084560\n0.023766\n0.032558\n0.222325\n0.051666\n1.000000\n0.000000\n0.000000\n0.000000\n0.063855\n\n\n16\n0.000000\n0.000000\n0.131770\n0.097706\n0.062796\n0.000000\n0.070146\n0.000000\n0.143340\n0.052482\n0.050745\n0.000000\n0.000000\n0.000000\n0.125587\n0.000000\n1.000000\n0.000000\n0.064853\n0.000000\n\n\n17\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.164087\n\n\n18\n0.000000\n0.000000\n0.000000\n0.108934\n0.070012\n0.000000\n0.030029\n0.000000\n0.000000\n0.058512\n0.056576\n0.063132\n0.000000\n0.000000\n0.090265\n0.000000\n0.064853\n0.000000\n1.000000\n0.054013\n\n\n19\n0.117923\n0.062455\n0.106524\n0.058443\n0.000000\n0.025365\n0.126400\n0.027794\n0.016554\n0.023886\n0.088253\n0.034383\n0.047103\n0.022958\n0.081366\n0.063855\n0.000000\n0.164087\n0.054013\n1.000000\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n25 4. Graph\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Membuat grafik jaringan\nG = nx.Graph()\n\n# Menambahkan simpul (kalimat)\nfor i in range(len(cosine_sim_matrix2)):\n    G.add_node(i, label=df_cleaned2.index[i])  # Menggunakan label kalimat\n\n# Menambahkan tepian (hubungan) berdasarkan kesamaan kosinus\nfor i in range(len(cosine_sim_matrix2)):\n    for j in range(i+1, len(cosine_sim_matrix2)):\n        similarity = cosine_sim_matrix2[i][j]\n        if similarity &gt; 0.1:  # Atur threshold sesuai kebutuhan\n            G.add_edge(i, j, weight=similarity)\n\n# Menggambar grafik jaringan\npos = nx.spring_layout(G, seed=42)  # Menggunakan layout spring\nlabels = nx.get_node_attributes(G, 'label')\n\nnx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=500, font_size=8, font_color='black')\nnx.draw_networkx_edge_labels(G, pos, edge_labels={(i, j): f\"{similarity:.2f}\" for i, j, similarity in G.edges(data='weight')})\n\nplt.show()\n\n\n\n\n\n\n26 5. Closeness Centrality\nPada proses ini Closeness Centrality digunakan untuk menghitung bobot sebuah node berdasarkan jumlah jarak terpendek antara node(i) dengan node lainnya. Berikut rumus Closeness Centrality\n\\[\nC_c(i)=\\frac{n-1}{\\sum_{j=1}^n d(i, j)}\n\\]\n\nimport networkx as nx\n\ncloseness_centrality = nx.closeness_centrality(G)\n\nsorted_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)\n\nfor node, closeness in sorted_closeness:\n    print(f\"Simpul {node}: Closeness Centrality = {closeness:.4f}\")\n\nSimpul 6: Closeness Centrality = 0.4346\nSimpul 15: Closeness Centrality = 0.4111\nSimpul 10: Closeness Centrality = 0.3900\nSimpul 3: Closeness Centrality = 0.3803\nSimpul 2: Closeness Centrality = 0.3710\nSimpul 13: Closeness Centrality = 0.3710\nSimpul 19: Closeness Centrality = 0.3622\nSimpul 0: Closeness Centrality = 0.3537\nSimpul 14: Closeness Centrality = 0.3380\nSimpul 1: Closeness Centrality = 0.3236\nSimpul 16: Closeness Centrality = 0.3236\nSimpul 8: Closeness Centrality = 0.3169\nSimpul 4: Closeness Centrality = 0.2716\nSimpul 18: Closeness Centrality = 0.2716\nSimpul 17: Closeness Centrality = 0.2623\nSimpul 9: Closeness Centrality = 0.2414\nSimpul 11: Closeness Centrality = 0.2414\nSimpul 12: Closeness Centrality = 0.2414\nSimpul 5: Closeness Centrality = 0.0000\nSimpul 7: Closeness Centrality = 0.0000\n\n\n\n\n27 6. PageRank\nPagerank merupakan suatu proses mengukur atau mencari nilai penting dalam suatu dokumen\n\\[\n\\operatorname{PR}\\left(S_i\\right)=\\frac{1-\\alpha}{\\text { NodeCount }}+\\alpha \\sum_{S_j} \\in \\text { Neighbors } S_i \\frac{\\operatorname{PR}\\left(S_j\\right)}{\\operatorname{CountEdge}\\left(S_j\\right)}\n\\]\nKeterangan: \\[\n\\begin{array}{ll}\nP R\\left(S_i\\right) & \\text { : Nilai PageRank untuk kaliamt } \\mathrm{Si} \\\\\n\\operatorname{PR}\\left(S_j\\right) & \\text { : Nilai PageRank dari vertex yang bertetangga dengan } \\mathrm{Si} \\\\\n\\text { CountEdge }\\left(S_j\\right) & \\text { : Jumlah edge dari kalimat } \\mathrm{Sj} \\\\\n\\alpha_i  & \\text { : Damping faktor yang nilainya antara 0 dan 1 } \\\\\n\\end{array}\n\\]\n\nG = nx.DiGraph(nx.path_graph(4))\npr = nx.pagerank(G, alpha=0.9)\npr\n\n{0: 0.1724140124772394,\n 1: 0.3275859875227606,\n 2: 0.3275859875227606,\n 3: 0.1724140124772394}\n\n\n\n\n28 7. EigenVector\nEigenVector digunakan untuk menghitung sentralitas sebuah node dengan menambahkan sentralitas pendahulunya. Berikut nilai persamaan dari EigenVector\n\\[\n\\lambda x_i=\\sum_{j \\rightarrow i} x_j\n\\]\n\nG = nx.path_graph(4)\ncentrality = nx.eigenvector_centrality(G)\nsorted((v, f\"{c:0.2f}\") for v, c in centrality.items())\n\n[(0, '0.37'), (1, '0.60'), (2, '0.60'), (3, '0.37')]\n\n\nKalimat penting pada Dokumen 2 berdasarkan nilai EigenVector\n\nimport networkx as nx\n\n# Membuat grafik jaringan (contoh: grafik jalur)\nG = nx.path_graph(4)\n\n# Menghitung eigenvector centrality\ncentrality = nx.eigenvector_centrality(G)\n\n# Data berita (dalam bentuk daftar)\nberita =df_cleaned2['Tokenisasi Dokumen2']\n\n# Menampilkan kalimat dari eigenvector centrality dan mengaitkannya dengan dokumen berita\nfor node, centrality_score in centrality.items():\n    if 0 &lt;= node &lt; len(berita):\n        kalimat = f\"Kalimat berita2: '{berita[node]}' memiliki Eigenvector Centrality sebesar {centrality_score:.2f}\"\n        print(kalimat)\n\nKalimat berita2: 'brand apparel olahraga armour mengadakan kompetisi lari mile dalam rangkap hari lari sedunia' memiliki Eigenvector Centrality sebesar 0.37\nKalimat berita2: 'kegiatan yang diadakan di senayan jakarta ini diikuti sebanyak peserta mulai dari orang dewasa hingga anakanak' memiliki Eigenvector Centrality sebesar 0.60\nKalimat berita2: 'armour juga mengundang komunitas lari' memiliki Eigenvector Centrality sebesar 0.60\nKalimat berita2: 'kita undang komunitas lari' memiliki Eigenvector Centrality sebesar 0.37\n\n\n\n\n29 8. Mencari Kata Kunci Pada Dokumen 2\nNilai TF-IDF Kata Kunci Pada Dokumen 2\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\n# Data kalimat (contoh)\nkalimat = df_cleaned2['Tokenisasi Dokumen2']\n\n# Membuat objek TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer()\n\n# Menghitung TF-IDF\ntfidf_matrix = tfidf_vectorizer.fit_transform(kalimat)\n\n# Mengonversi matriks TF-IDF ke DataFrame Pandas\ntfidf_kata2 = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Mengganti NaN dengan 0\ntfidf_kata2 = tfidf_kata2.fillna(0)\n\n# Menampilkan nilai TF-IDF dengan kata-kata\ntfidf_values_with_words2 = pd.concat([pd.Series(tfidf_vectorizer.get_feature_names_out(), name='Kata'),\n                                     tfidf_kata2], axis=1)\n\n# Menampilkan tabel TF-IDF dengan kata-kata\ntfidf_values_with_words2\n\n\n  \n    \n\n\n\n\n\n\nKata\nacaranya\nadapun\nade\nagenda\najang\nakan\namerika\nanakanak\napalagi\n...\nujar\nundang\nuntuk\nurutanranking\nutama\nvideo\nwaktu\nwindow\nyaitu\nyang\n\n\n\n\n0\nacaranya\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n...\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.00000\n\n\n1\nadapun\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.289316\n0.0\n...\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.16964\n\n\n2\nade\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n...\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.00000\n\n\n3\nagenda\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n...\n0.0\n0.568672\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.00000\n\n\n4\najang\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n...\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.00000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n202\nvideo\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n203\nwaktu\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n204\nwindow\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n205\nyaitu\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n206\nyang\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n207 rows × 208 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nNilai Cosinus Similarity Pada Dokumen 2\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Drop the 'Kata' column before calculating cosine similarity\ntfidf_vectors_only = tfidf_values_with_words2.drop(columns=['Kata'])\n\n# Handling NaN values by filling them with 0\ntfidf_vectors_only = tfidf_vectors_only.fillna(0)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_vectors_only, tfidf_vectors_only)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df2 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_values_with_words2.index, index=tfidf_values_with_words2.index)\ncosine_sim_df2\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n\n\n\n\n0\n1.000000\n0.00000\n0.234330\n0.175971\n0.000000\n0.000000\n0.028339\n0.000000\n0.045604\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.000000\n1.00000\n0.000000\n0.000000\n0.047170\n0.036705\n0.095177\n0.040219\n0.051276\n0.112246\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.234330\n0.00000\n1.000000\n0.430792\n0.000000\n0.000000\n0.051199\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.175971\n0.00000\n0.430792\n1.000000\n0.105478\n0.000000\n0.134385\n0.000000\n0.000000\n0.088153\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n0.000000\n0.04717\n0.000000\n0.105478\n1.000000\n0.000000\n0.029076\n0.000000\n0.039265\n0.056656\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n202\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n203\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n204\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n205\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n206\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n207 rows × 207 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nGraph Kata Kunci pada Dokumen 2\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Assuming tfidf_kata1 is your DataFrame with TF-IDF values\n# and top_keywords is the top keywords for each document\n\n# Handling NaN values by filling them with 0\ntfidf_kata2 = tfidf_kata2.fillna(0)\n\n# Calculate the sum of TF-IDF values for each term\nterm_sums = tfidf_kata2.sum()\n\n# Sort terms based on their sum of TF-IDF values in descending order\nsorted_terms = term_sums.sort_values(ascending=False)\n\n# Extract the top N keywords (adjust N as needed)\nN = 1\ntop_keywords = sorted_terms.head(N)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_kata2, tfidf_kata2)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df2 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_kata2.index, index=tfidf_kata2.index)\n\n# Creating a graph\nG = nx.Graph()\n\n# Adding nodes to the graph with top keywords as labels\nfor document in tfidf_kata2.index:\n    keywords_indices = tfidf_kata2.loc[document].values.argsort()[-N:][::-1]\n    keywords_list = tfidf_kata2.columns[keywords_indices].tolist()\n    G.add_node(document, label=\", \".join(map(str, keywords_list)))\n\n\n# Adding edges to the graph\nfor i in range(len(cosine_sim_df2.index)):\n    for j in range(i + 1, len(cosine_sim_df2.index)):\n        G.add_edge(cosine_sim_df2.index[i], cosine_sim_df2.index[j], weight=cosine_sim_df2.iloc[i, j])\n\n# Visualizing the graph\npos = nx.spring_layout(G)  # You can use different layouts depending on your preference\nedge_labels = nx.get_edge_attributes(G, 'weight')\n\nplt.figure(figsize=(12, 10))\nnx.draw(G, pos, with_labels=True, font_size=10, font_color=\"black\", node_size=800, node_color=\"skyblue\", font_weight=\"bold\", edge_color=\"gray\")\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color=\"red\", font_size=8)\nplt.title('Document Similarity Graph with Top Keywords')\nplt.show()\n\n\n\n\nKata Kunci Pada Dokumen 2\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n# Assuming tfidf_kata1 is your DataFrame with TF-IDF values\n# and top_keywords is the top keywords for each document\n\n# Handling NaN values by filling them with 0\ntfidf_kata2 = tfidf_kata2.fillna(0)\n\n# Calculate the sum of TF-IDF values for each term\nterm_sums = tfidf_kata2.sum()\n\n# Sort terms based on their sum of TF-IDF values in descending order\nsorted_terms = term_sums.sort_values(ascending=False)\n\n# Extract the top N keywords (adjust N as needed)\nN = 1\ntop_keywords = sorted_terms.head(N)\n\n# Menghitung kesamaan kosinus antara kalimat-kalimat\ncosine_sim_matrix = cosine_similarity(tfidf_kata2, tfidf_kata2)\n\n# Menampilkan matriks kesamaan kosinus\ncosine_sim_df2 = pd.DataFrame(cosine_sim_matrix, columns=tfidf_kata2.index, index=tfidf_kata2.index)\n\n# Create a list of nodes sorted by the highest TF-IDF value\nsorted_nodes = sorted(tfidf_kata2.index, key=lambda x: tfidf_kata2.loc[x].max(), reverse=True)\n\n# Creating a graph\nG = nx.Graph()\n\n# Adding nodes to the graph with top keywords as labels\nfor document in sorted_nodes:\n    keywords_indices = tfidf_kata2.loc[document].values.argsort()[-N:][::-1]\n    keywords_list = tfidf_kata2.columns[keywords_indices].tolist()\n    keywords_values = tfidf_kata2.loc[document, keywords_list].tolist()\n\n    # Sorting keywords and values in descending order\n    sorted_keywords_values = sorted(zip(keywords_list, keywords_values), key=lambda x: x[1], reverse=True)\n\n    node_label = \", \".join([f\"{kw} ({val:.4f})\" for kw, val in sorted_keywords_values])\n    G.add_node(document, label=node_label)\n\n# Adding edges to the graph\nfor i in range(len(cosine_sim_df2.index)):\n    for j in range(i + 1, len(cosine_sim_df2.index)):\n        G.add_edge(cosine_sim_df2.index[i], cosine_sim_df2.index[j], weight=cosine_sim_df2.iloc[i, j])\n\n# Visualizing the graph\npos = nx.spring_layout(G)  # You can use different layouts depending on your preference\nedge_labels = nx.get_edge_attributes(G, 'weight')\nnode_labels = nx.get_node_attributes(G, 'label')\n\nplt.figure(figsize=(12, 10))\nnx.draw(G, pos, with_labels=True, font_size=10, font_color=\"black\", node_size=800, node_color=\"skyblue\", font_weight=\"bold\", edge_color=\"gray\")\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color=\"red\", font_size=8)\nnx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8, font_color=\"green\")\n\n# Display top keywords and values for each node\nfor node, label in node_labels.items():\n    print(f\"Node {node} Keywords and Values: {label}\")\n\nplt.title('Document Similarity Graph with Top Keywords and Values (Sorted)')\nplt.show()\n\nNode 3 Keywords and Values: undang (0.5687)\nNode 2 Keywords and Values: mengundang (0.5438)\nNode 17 Keywords and Values: reuni (0.5311)\nNode 18 Keywords and Values: dilanda (0.4294)\nNode 4 Keywords and Values: terbatas (0.4158)\nNode 0 Keywords and Values: lari (0.4047)\nNode 7 Keywords and Values: pemanasan (0.4043)\nNode 16 Keywords and Values: realita (0.3852)\nNode 5 Keywords and Values: acaranya (0.3690)\nNode 6 Keywords and Values: ade (0.3567)\nNode 19 Keywords and Values: running (0.3515)\nNode 9 Keywords and Values: scroll (0.3475)\nNode 12 Keywords and Values: dikuti (0.3201)\nNode 15 Keywords and Values: maka (0.2958)\nNode 13 Keywords and Values: maupun (0.2928)\nNode 1 Keywords and Values: diadakan (0.2893)\nNode 14 Keywords and Values: berlari (0.2636)\nNode 8 Keywords and Values: kecepatan (0.2408)\nNode 11 Keywords and Values: pendaftarannya (0.2337)\nNode 10 Keywords and Values: membantu (0.2094)"
  },
  {
    "objectID": "kata_kunci.html",
    "href": "kata_kunci.html",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "",
    "text": "3 MEMANGGIL DATA DALAM BENTUK TABEL\nAgar mempermudah program dalam memproses data\nimport pandas as pd\n\n# Ganti 'nama_file.csv' dengan nama file CSV yang diupload\nnama_file_csv = 'berita-cnn.csv'\n\n# Load data dari CSV\ndf = pd.read_csv(nama_file_csv)\n\n# Tampilkan data untuk memastikan berhasil di-load\ndf\n\n\n  \n    \n\n\n\n\n\n\njudul\nberita\n\n\n\n\n0\nSuami di Baubau Aniaya Istri yang Lagi Hamil ...\nAksi kekerasan dalam rumah tangga (KDRT) di Ba...\n\n\n1\n2 Ribu Personel Polisi Amankan Debat Capres-C...\nSebanyak 2.000 personel kepolisian dikerahkan ...\n\n\n2\nPrediksi Jurus Anies, Prabowo, Ganjar di Deba...\nDaftar Isi Anies Baswedan Prabowo Subianto Gan...\n\n\n3\nAyah Bunuh Anak di Jagakarsa Berdiam Diri di ...\nPolisi mengungkap Panca Darmansyah alias Panca...\n\n\n4\nKPU Batal Selenggarakan Nobar Debat Capres da...\nKomisi Pemilihan Umum (KPU) batal menggelar po...\n\n\n5\nPolisi Sebut Bukan SYL yang Buat Laporan Duga...\nPolda Metro Jaya menyebut laporan terkait duga...\n\n\n6\nLSI Denny JA: Prabowo-Gibran Bakal Menang Tel...\nHasil survei Lingkaran Survei Indonesia (LSI) ...\n\n\n7\nJokowi Tetap Mau Tampung Pengungsi Rohingya u...\nPresiden Joko Widodo menyatakan Indonesia akan...\n\n\n8\nGibran Bakal Fokus Kampanye Pilpres di Kandan...\nCalon wakil presiden nomor urut 2 Gibran Rakab...\n\n\n9\nKasasi Ditolak, Hakim Agung Sudrajad Dimyati ...\nMahkamah Agung (MA) menolak kasasi Sudrajad Di...\n\n\n10\nPemerintah Minta Masyarakat Patuhi Protokol C...\nMenteri Koordinator Pemberdayaan Manusia dan K...\n\n\n11\nFormasi Duduk Capres hingga Tim Pendukung di ...\nDaftar Isi VIP A Baris 1 (kapasitas 17 orang) ...\n\n\n12\nTPN Ganjar-Mahfud soal Survei Pilpres 2024 Sa...\nDeputi Politik 5.0 Tim Pemenangan Nasional (TP...\n\n\n13\nTKN Prabowo-Gibran Kumpulkan Aktivis 98 Jelan...\nJelang debat resmi calon presiden dan calon wa...\n\n\n14\nDaftar Rekayasa Lalu Lintas di Sekitar KPU Sa...\nDitlantas Polda Metro Jaya menyiapkan rekayasa...\n\n\n15\nGempa Bumi M 5,8 Guncang Riau, Getaran Terasa...\nGempa bumi dengan kekuatan M 5,8 mengguncang w...\n\n\n16\nVIDEO: Jokowi Respons Kritik BEM UGM: Kita Pu...\nPresiden Joko Widodo mengingatkan semua pihak ...\n\n\n17\nMotif Ingin Perkaya Diri Beratkan Tuntutan 14...\nJaksa Penuntut Umum pada Komisi Pemberantasan ...\n\n\n18\nTilang Manual Tidak Berlaku Saat Libur Nataru\nKapolri Jenderal Listyo Sigit Prabowo menyatak...\n\n\n19\nVIDEO: Jokowi Respons Pernyataan Diklaim Masu...\nPresiden Joko Widodo menanggapi pernyataan Ket..."
  },
  {
    "objectID": "kata_kunci.html#instalasi",
    "href": "kata_kunci.html#instalasi",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "2.1 INSTALASI",
    "text": "2.1 INSTALASI\n\n!pip install requests\n!pip install beautifulsoup4\n!pip install tqdm\n!pip install Rouge\n\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\nRequirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\nCollecting Rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Rouge) (1.16.0)\nInstalling collected packages: Rouge\nSuccessfully installed Rouge-1.0.1\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom tqdm.auto import tqdm"
  },
  {
    "objectID": "kata_kunci.html#crawling-berita-cnnindonesia",
    "href": "kata_kunci.html#crawling-berita-cnnindonesia",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "2.2 CRAWLING BERITA CNNINDONESIA",
    "text": "2.2 CRAWLING BERITA CNNINDONESIA\n\nfrom os import replace\ndef cnnnews(page):\n\n    data = {'judul': [], 'berita': []}\n    for i in tqdm(range(1, page+1)):\n      url = f\"https://www.cnnindonesia.com/nasional/indeks/3/{i}\"\n      r = requests.get(url)\n      request = r.content\n      soup = BeautifulSoup(request, 'html.parser')\n      soup = soup.find('div', {'class': 'flex flex-col gap-5'})\n      news = soup.findAll('article', {'class': 'flex-grow'})\n      # news = soup.findAll('a', {'aria-label': 'link description'})\n\n      for new in tqdm(news):\n        a_element = new.find('a', {'aria-label': 'link description'})['href']\n        detail_request = requests.get(a_element)\n        detail_soup = BeautifulSoup(detail_request.content, 'html.parser')\n\n        judul = detail_soup.find('h1', {'class': 'leading-9'})\n        berita = detail_soup.find('div', {'class': 'detail-text'})\n\n        if judul and berita:\n          judul = judul.text\n          berita = berita.text\n          noise = detail_soup.find('strong').text\n\n          berita = berita.replace(\"ADVERTISEMENT\", \"\").replace(\"SCROLL TO CONTINUE WITH CONTENT\", \"\").replace(\"Lihat Juga :\", \"\").replace(\"Bagikan\", \"\").replace(noise, \"\").replace(\"-- \", \"\").replace(\"--\", \"\")\n          berita = ' '.join(berita.split())\n          data[\"judul\"].append(judul)\n          data[\"berita\"].append(berita)\n\n    df = pd.DataFrame(data)\n    df.to_csv(\"berita-cnn.csv\", index=False)\n\n    return df\n\n\ncnnnews(2)\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n\n\n\n\n\n\njudul\nberita\n\n\n\n\n0\nSuami di Baubau Aniaya Istri yang Lagi Hamil ...\nAksi kekerasan dalam rumah tangga (KDRT) di Ba...\n\n\n1\n2 Ribu Personel Polisi Amankan Debat Capres-C...\nSebanyak 2.000 personel kepolisian dikerahkan ...\n\n\n2\nPrediksi Jurus Anies, Prabowo, Ganjar di Deba...\nDaftar Isi Anies Baswedan Prabowo Subianto Gan...\n\n\n3\nAyah Bunuh Anak di Jagakarsa Berdiam Diri di ...\nPolisi mengungkap Panca Darmansyah alias Panca...\n\n\n4\nKPU Batal Selenggarakan Nobar Debat Capres da...\nKomisi Pemilihan Umum (KPU) batal menggelar po...\n\n\n5\nPolisi Sebut Bukan SYL yang Buat Laporan Duga...\nPolda Metro Jaya menyebut laporan terkait duga...\n\n\n6\nLSI Denny JA: Prabowo-Gibran Bakal Menang Tel...\nHasil survei Lingkaran Survei Indonesia (LSI) ...\n\n\n7\nJokowi Tetap Mau Tampung Pengungsi Rohingya u...\nPresiden Joko Widodo menyatakan Indonesia akan...\n\n\n8\nGibran Bakal Fokus Kampanye Pilpres di Kandan...\nCalon wakil presiden nomor urut 2 Gibran Rakab...\n\n\n9\nKasasi Ditolak, Hakim Agung Sudrajad Dimyati ...\nMahkamah Agung (MA) menolak kasasi Sudrajad Di...\n\n\n10\nPemerintah Minta Masyarakat Patuhi Protokol C...\nMenteri Koordinator Pemberdayaan Manusia dan K...\n\n\n11\nFormasi Duduk Capres hingga Tim Pendukung di ...\nDaftar Isi VIP A Baris 1 (kapasitas 17 orang) ...\n\n\n12\nTPN Ganjar-Mahfud soal Survei Pilpres 2024 Sa...\nDeputi Politik 5.0 Tim Pemenangan Nasional (TP...\n\n\n13\nTKN Prabowo-Gibran Kumpulkan Aktivis 98 Jelan...\nJelang debat resmi calon presiden dan calon wa...\n\n\n14\nDaftar Rekayasa Lalu Lintas di Sekitar KPU Sa...\nDitlantas Polda Metro Jaya menyiapkan rekayasa...\n\n\n15\nGempa Bumi M 5,8 Guncang Riau, Getaran Terasa...\nGempa bumi dengan kekuatan M 5,8 mengguncang w...\n\n\n16\nVIDEO: Jokowi Respons Kritik BEM UGM: Kita Pu...\nPresiden Joko Widodo mengingatkan semua pihak ...\n\n\n17\nMotif Ingin Perkaya Diri Beratkan Tuntutan 14...\nJaksa Penuntut Umum pada Komisi Pemberantasan ...\n\n\n18\nTilang Manual Tidak Berlaku Saat Libur Nataru\nKapolri Jenderal Listyo Sigit Prabowo menyatak...\n\n\n19\nVIDEO: Jokowi Respons Pernyataan Diklaim Masu...\nPresiden Joko Widodo menanggapi pernyataan Ket..."
  },
  {
    "objectID": "kata_kunci.html#data-berita",
    "href": "kata_kunci.html#data-berita",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "3.1 DATA BERITA",
    "text": "3.1 DATA BERITA\nPada Data berita yang di crawling diambil 1 berita pada indeks 16 yang akan diproses\n\nberita = df['berita'].iloc[15]\nberita\n\n'Gempa bumi dengan kekuatan M 5,8 mengguncang wilayah Riau, pada Senin (11/12) pukul 17.16 Wib. Badan Meteorologi, Klimatologi dan Geofisika (BMKG) mengumumkan gempa tektonik itu tepatnya mengguncang wilayah wilayah Kuantan Singingi, Riau. Hasil analisis BMKG menunjukkan gempa bumi ini memiliki parameter update dengan magnitudo M5,5. Episenter gempa bumi terletak pada koordinat 0,52 derajat Lintang Selatan, 101,30 derajat bujur timur. \"Atau tepatnya berlokasi di darat wilayah Kuantan Singingi, Riau pada kedalaman 246 km,\" kata Kepala Pusat Gempabumi dan Tsunami BMKG, Daryono. Namun dia memastikan gempa yang dirasakan hingga Padang itu tidak berpotensi tsunami. \"Gempa bumi ini berdampak dan dirasakan di daerah Padang dengan skala intensitas II MMI (getaran dirasakan oleh beberapa orang, benda-benda ringan yang digantung bergoyang). Hasil pemodelan menunjukkan bahwa gempa bumi ini tidak berpotensi tsunami,\" kata Daryono. PVMBG Catat Peningkatan Gempa Tektonik Lokal di Gunung Salak Bogor Lebih lanjut, hingga pukul 17.40 WIB, hasil monitoring BMKG belum menunjukkan adanya aktivitas gempa bumi susulan (aftershock). Daryono menjelaskan gempa bumi yang terjadi merupakan jenis gempa bumi menengah akibat aktivitas deformasi batuan dalam Lempeng Indo-Australia yang tersubduksi ke bawah Pulau Sumatra (Intra-Slab Event). Hasil analisis mekanisme sumber menunjukkan bahwa gempa bumi memiliki mekanisme pergerakan naik (thrust fault). Masyarakat diminta untuk menghindari dari bangunan yang retak atau rusak diakibatkan oleh gempa. \"Periksa dan pastikan bangunan tempat tinggal anda cukup tahan gempa, ataupun tidak ada kerusakan akibat getaran gempa yang membahayakan kestabilan bangunan sebelum anda kembali ke dalam rumah,\" demikian Daryono. BNPB: Gunung Merapi Masih Aktif, Sempat Muntahkan Awan Panas (tim/DAL) [Gambas:Video CNN]'"
  },
  {
    "objectID": "kata_kunci.html#preprocessingg",
    "href": "kata_kunci.html#preprocessingg",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "3.2 PREPROCESSINGG",
    "text": "3.2 PREPROCESSINGG\nDilakukan Preprocessing data dengan stopword dan tokenisasi pada berita\n\nimport pandas as pd\nimport nltk\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n\nnltk.download('punkt')\nnltk.download(\"stopwords\")\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\nTrue\n\n\n\n3.2.1 Melakukan Stopword untuk menghapus karakter tidak penting dalam suatu kalimmat berita\n\ndef preprocessing(text):\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'[^\\w\\s.]', '', text)\n    text = text.lower()\n\n    stop_words = set(stopwords.words('indonesian'))\n    words = text.split()\n    filtered_words = [word for word in words if word.lower() not in stop_words]\n\n    preprocessing_text = ' '.join(filtered_words)\n\n    return preprocessing_text\n\n\nberita = preprocessing(berita)\nprint(berita)\n\ngempa bumi kekuatan m mengguncang wilayah riau senin . wib. badan meteorologi klimatologi geofisika bmkg mengumumkan gempa tektonik tepatnya mengguncang wilayah wilayah kuantan singingi riau. hasil analisis bmkg gempa bumi memiliki parameter update magnitudo m. episenter gempa bumi terletak koordinat derajat lintang selatan derajat bujur timur. tepatnya berlokasi darat wilayah kuantan singingi riau kedalaman km kepala pusat gempabumi tsunami bmkg daryono. gempa dirasakan padang berpotensi tsunami. gempa bumi berdampak dirasakan daerah padang skala intensitas ii mmi getaran dirasakan orang bendabenda ringan digantung bergoyang. hasil pemodelan gempa bumi berpotensi tsunami daryono. pvmbg catat peningkatan gempa tektonik lokal gunung salak bogor . wib hasil monitoring bmkg aktivitas gempa bumi susulan aftershock. daryono gempa bumi jenis gempa bumi menengah akibat aktivitas deformasi batuan lempeng indoaustralia tersubduksi pulau sumatra intraslab event. hasil analisis mekanisme sumber gempa bumi memiliki mekanisme pergerakan thrust fault. masyarakat menghindari bangunan retak rusak diakibatkan gempa. periksa pastikan bangunan tinggal tahan gempa kerusakan akibat getaran gempa membahayakan kestabilan bangunan rumah daryono. bnpb gunung merapi aktif muntahkan awan panas timdal gambasvideo cnn\n\n\n\n\n3.2.2 Memisahkan Kalimat dengan Kalimat\n\nkalimat = nltk.sent_tokenize(berita)\nkalimat = [sentence.replace('.', '') for sentence in kalimat]\nprint(kalimat)\n\n['gempa bumi kekuatan m mengguncang wilayah riau senin ', 'wib', 'badan meteorologi klimatologi geofisika bmkg mengumumkan gempa tektonik tepatnya mengguncang wilayah wilayah kuantan singingi riau', 'hasil analisis bmkg gempa bumi memiliki parameter update magnitudo m episenter gempa bumi terletak koordinat derajat lintang selatan derajat bujur timur', 'tepatnya berlokasi darat wilayah kuantan singingi riau kedalaman km kepala pusat gempabumi tsunami bmkg daryono', 'gempa dirasakan padang berpotensi tsunami', 'gempa bumi berdampak dirasakan daerah padang skala intensitas ii mmi getaran dirasakan orang bendabenda ringan digantung bergoyang', 'hasil pemodelan gempa bumi berpotensi tsunami daryono', 'pvmbg catat peningkatan gempa tektonik lokal gunung salak bogor ', 'wib hasil monitoring bmkg aktivitas gempa bumi susulan aftershock', 'daryono gempa bumi jenis gempa bumi menengah akibat aktivitas deformasi batuan lempeng indoaustralia tersubduksi pulau sumatra intraslab event', 'hasil analisis mekanisme sumber gempa bumi memiliki mekanisme pergerakan thrust fault', 'masyarakat menghindari bangunan retak rusak diakibatkan gempa', 'periksa pastikan bangunan tinggal tahan gempa kerusakan akibat getaran gempa membahayakan kestabilan bangunan rumah daryono', 'bnpb gunung merapi aktif muntahkan awan panas timdal gambasvideo cnn']\n\n\n\n\n3.2.3 Memisahkan Kalimat menjadi suatu term pada kalimat berita\n\nkata = word_tokenize(berita)\nkata = [k.lower() for k in kata if k != '.']\nkata = list(set(kata))\nprint(kata)\n\n['menengah', 'berpotensi', 'gempa', 'kestabilan', 'bogor', 'wilayah', 'magnitudo', 'parameter', 'pvmbg', 'monitoring', 'terletak', 'kedalaman', 'meteorologi', 'salak', 'bangunan', 'episenter', 'gempabumi', 'merapi', 'senin', 'indoaustralia', 'ii', 'timdal', 'tersubduksi', 'skala', 'thrust', 'aftershock', 'bnpb', 'pusat', 'lintang', 'derajat', 'diakibatkan', 'akibat', 'm', 'padang', 'periksa', 'lokal', 'memiliki', 'koordinat', 'retak', 'masyarakat', 'tahan', 'geofisika', 'peningkatan', 'tepatnya', 'awan', 'darat', 'pastikan', 'badan', 'event', 'lempeng', 'bergoyang', 'pergerakan', 'berdampak', 'gambasvideo', 'klimatologi', 'bendabenda', 'm.', 'update', 'daryono', 'gunung', 'pemodelan', 'ringan', 'wib', 'rumah', 'bujur', 'kerusakan', 'sumber', 'tinggal', 'digantung', 'catat', 'orang', 'pulau', 'mengumumkan', 'sumatra', 'cnn', 'timur', 'aktivitas', 'selatan', 'fault', 'singingi', 'jenis', 'intraslab', 'intensitas', 'rusak', 'kuantan', 'muntahkan', 'menghindari', 'mmi', 'bmkg', 'mengguncang', 'getaran', 'mekanisme', 'kekuatan', 'aktif', 'bumi', 'berlokasi', 'km', 'deformasi', 'panas', 'analisis', 'tsunami', 'batuan', 'dirasakan', 'susulan', 'daerah', 'tektonik', 'riau', 'membahayakan', 'hasil', 'kepala']"
  },
  {
    "objectID": "kata_kunci.html#nilai-matriks-kata",
    "href": "kata_kunci.html#nilai-matriks-kata",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "3.3 NILAI MATRIKS KATA",
    "text": "3.3 NILAI MATRIKS KATA\n\n3.3.1 Menampilkan Jumlah Kedekatan atau ketetanggaan suatu kata dengan kata yang lain\n\nmatrikskata = pd.DataFrame(0, index=kata, columns=kata)\n\n\nfor sent in kalimat:\n    kata_kalimat = word_tokenize(sent)\n    for i in range(len(kata_kalimat)-1):\n        matrikskata.at[kata_kalimat[i], kata_kalimat[i+1]] += 1 # jika kata pada sebelah kanan\n        matrikskata.at[kata_kalimat[i+1], kata_kalimat[i]] += 1 # jika kata pada sebelah kiri\n\n\nmatrikskata\n\n\n  \n    \n\n\n\n\n\n\nmenengah\nberpotensi\ngempa\nkestabilan\nbogor\nwilayah\nmagnitudo\nparameter\npvmbg\nmonitoring\n...\ntsunami\nbatuan\ndirasakan\nsusulan\ndaerah\ntektonik\nriau\nmembahayakan\nhasil\nkepala\n\n\n\n\nmenengah\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nberpotensi\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\ngempa\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n1\n0\n0\n2\n0\n1\n0\n0\n\n\nkestabilan\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\nbogor\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\ntektonik\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nriau\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nmembahayakan\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nhasil\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nkepala\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n110 rows × 110 columns"
  },
  {
    "objectID": "kata_kunci.html#cosinus-similarity",
    "href": "kata_kunci.html#cosinus-similarity",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "4.1 COSINUS SIMILARITY",
    "text": "4.1 COSINUS SIMILARITY\nMenampilkan nilai Cosinus Similaritas pada setiap kata atau term\n\ncosine = cosine_similarity(matrikskata, matrikskata)\n\n\nsimilarity = pd.DataFrame(cosine, columns=matrikskata.index, index=matrikskata.index)\nsimilarity\n\n\n  \n    \n\n\n\n\n\n\nmenengah\nberpotensi\ngempa\nkestabilan\nbogor\nwilayah\nmagnitudo\nparameter\npvmbg\nmonitoring\n...\ntsunami\nbatuan\ndirasakan\nsusulan\ndaerah\ntektonik\nriau\nmembahayakan\nhasil\nkepala\n\n\n\n\nmenengah\n1.000000\n0.288675\n0.636396\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.000000\n0.500000\n0.000000\n0.00000\n0.0\n0.00000\n0.000000\n0.0\n\n\nberpotensi\n0.288675\n1.000000\n0.367423\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.166667\n0.288675\n0.288675\n0.00000\n0.0\n0.00000\n0.000000\n0.0\n\n\ngempa\n0.636396\n0.367423\n1.000000\n0.070711\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.070711\n...\n0.075593\n0.0\n0.040825\n0.636396\n0.070711\n0.00000\n0.0\n0.00000\n0.037796\n0.0\n\n\nkestabilan\n0.000000\n0.000000\n0.070711\n1.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.000000\n0.000000\n0.000000\n0.00000\n0.0\n0.00000\n0.000000\n0.0\n\n\nbogor\n0.000000\n0.000000\n0.000000\n0.000000\n1.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.000000\n0.000000\n0.000000\n0.00000\n0.0\n0.00000\n0.000000\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\ntektonik\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.333333\n0.000000\n0.000000\n1.00000\n0.0\n0.57735\n0.000000\n0.0\n\n\nriau\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n0.202031\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.000000\n0.000000\n0.000000\n0.00000\n1.0\n0.00000\n0.000000\n0.0\n\n\nmembahayakan\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.288675\n0.000000\n0.000000\n0.57735\n0.0\n1.00000\n0.000000\n0.0\n\n\nhasil\n0.000000\n0.000000\n0.037796\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.000000\n0.000000\n0.000000\n0.00000\n0.0\n0.00000\n1.000000\n0.0\n\n\nkepala\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.000000\n...\n0.000000\n0.0\n0.000000\n0.000000\n0.000000\n0.00000\n0.0\n0.00000\n0.000000\n1.0\n\n\n\n\n\n110 rows × 110 columns"
  },
  {
    "objectID": "kata_kunci.html#graph",
    "href": "kata_kunci.html#graph",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "4.2 GRAPH",
    "text": "4.2 GRAPH\n\nG = nx.DiGraph()\nfor i in range(len(cosine)):\n    G.add_node(i)\n\nfor i in range(len(cosine)):\n    for j in range(len(cosine)):\n        similarity = cosine[i][j]\n        if similarity &gt; 0.1 and i != j:\n            G.add_edge(i, j)\n\npos = nx.spring_layout(G)\nnx.draw_networkx_nodes(G, pos, node_size=500, node_color='b')\nnx.draw_networkx_edges(G, pos, edge_color='red', arrows=True)\nnx.draw_networkx_labels(G, pos)\n\nplt.show()"
  },
  {
    "objectID": "kata_kunci.html#pagerank",
    "href": "kata_kunci.html#pagerank",
    "title": "2  Mencari Kata Kunci pada Suatu Berita CNNIndonesia.com",
    "section": "4.3 PAGERANK",
    "text": "4.3 PAGERANK\n\npagerank = nx.pagerank(G)\n\nsorted_pagerank= sorted(pagerank.items(), key=lambda x: x[1], reverse=True)\nprint(\"Page Rank :\")\nfor node, pagerank in sorted_pagerank:\n    print(f\"Node {node}: {pagerank:.4f}\")\n\nPage Rank :\nNode 88: 0.0282\nNode 102: 0.0237\nNode 58: 0.0222\nNode 80: 0.0221\nNode 76: 0.0216\nNode 90: 0.0212\nNode 105: 0.0195\nNode 94: 0.0192\nNode 72: 0.0185\nNode 15: 0.0178\nNode 66: 0.0178\nNode 60: 0.0175\nNode 5: 0.0170\nNode 42: 0.0164\nNode 40: 0.0162\nNode 107: 0.0162\nNode 30: 0.0158\nNode 65: 0.0154\nNode 1: 0.0149\nNode 2: 0.0141\nNode 36: 0.0135\nNode 52: 0.0131\nNode 89: 0.0125\nNode 92: 0.0120\nNode 99: 0.0118\nNode 100: 0.0118\nNode 14: 0.0115\nNode 0: 0.0112\nNode 10: 0.0107\nNode 17: 0.0106\nNode 35: 0.0104\nNode 28: 0.0100\nNode 77: 0.0100\nNode 21: 0.0099\nNode 63: 0.0098\nNode 29: 0.0095\nNode 73: 0.0095\nNode 33: 0.0091\nNode 71: 0.0090\nNode 106: 0.0090\nNode 98: 0.0090\nNode 44: 0.0088\nNode 59: 0.0088\nNode 43: 0.0088\nNode 103: 0.0088\nNode 41: 0.0088\nNode 9: 0.0087\nNode 38: 0.0086\nNode 91: 0.0086\nNode 104: 0.0086\nNode 45: 0.0085\nNode 11: 0.0084\nNode 22: 0.0083\nNode 70: 0.0079\nNode 37: 0.0079\nNode 64: 0.0079\nNode 3: 0.0078\nNode 46: 0.0078\nNode 67: 0.0078\nNode 86: 0.0078\nNode 93: 0.0076\nNode 13: 0.0075\nNode 26: 0.0075\nNode 19: 0.0075\nNode 31: 0.0075\nNode 85: 0.0074\nNode 84: 0.0070\nNode 49: 0.0067\nNode 97: 0.0064\nNode 18: 0.0064\nNode 79: 0.0064\nNode 51: 0.0064\nNode 61: 0.0061\nNode 32: 0.0060\nNode 16: 0.0059\nNode 6: 0.0057\nNode 23: 0.0057\nNode 74: 0.0056\nNode 54: 0.0055\nNode 48: 0.0054\nNode 101: 0.0054\nNode 55: 0.0054\nNode 87: 0.0052\nNode 81: 0.0052\nNode 53: 0.0052\nNode 7: 0.0049\nNode 95: 0.0049\nNode 96: 0.0048\nNode 27: 0.0044\nNode 109: 0.0044\nNode 57: 0.0041\nNode 62: 0.0040\nNode 50: 0.0040\nNode 82: 0.0040\nNode 4: 0.0039\nNode 108: 0.0038\nNode 47: 0.0037\nNode 68: 0.0037\nNode 75: 0.0034\nNode 20: 0.0034\nNode 34: 0.0030\nNode 39: 0.0030\nNode 83: 0.0030\nNode 24: 0.0028\nNode 78: 0.0027\nNode 12: 0.0024\nNode 25: 0.0022\nNode 8: 0.0022\nNode 56: 0.0014\nNode 69: 0.0014\n\n\n\nprint(\"Tiga Node Tertinggi Page Rank :\")\nsentence = \"\"\nfor node, pagerank in sorted_pagerank[:3]:\n  top_sentence = kata[node]\n  sentence += top_sentence + \", \"\n  print(f\"Node {node}: Page Rank = {pagerank:.4f}\")\n  print(f\"Kalimat: {top_sentence}\")\n\nTiga Node Tertinggi Page Rank :\nNode 88: Page Rank = 0.0282\nKalimat: bmkg\nNode 102: Page Rank = 0.0237\nKalimat: dirasakan\nNode 58: Page Rank = 0.0222\nKalimat: daryono\n\n\n\nnews = df['berita'].iloc[16]\nprint('Berita yang digunakan : ')\nnews\n\nBerita yang digunakan : \n\n\n'Presiden Joko Widodo mengingatkan semua pihak mengenai etika dan sopan santun ketimuran dalam menyampaikan kritik atau pendapat. Jokowi mengatakan hal itu menanggapi kritik Badan Eksekutif Mahasiswa Keluarga Mahasiswa Universitas Gadjah Mada (BEM KM UGM) terhadap dirinya.'\n\n\n\nprint('Kata Kunci :', sentence)\n\nKata Kunci : bmkg, dirasakan, daryono,"
  }
]